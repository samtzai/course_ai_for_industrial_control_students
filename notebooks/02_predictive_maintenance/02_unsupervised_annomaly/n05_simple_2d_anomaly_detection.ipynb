{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0267199",
   "metadata": {},
   "source": [
    "# üéØ Simple 2D Anomaly Detection Tutorial\n",
    "\n",
    "## **Gaussian Multivariate Anomaly Detection**\n",
    "\n",
    "### **Main Goal:**\n",
    "Learn to detect anomalies in 2D industrial data using a simple Gaussian multivariate method. This tutorial demonstrates how to identify abnormal operating conditions using statistical modeling with easy-to-visualize 2D data.\n",
    "\n",
    "### **Key Learning Objectives:**\n",
    "- **2D Data Visualization**: Understand anomaly patterns in 2D space\n",
    "- **Gaussian Distribution**: Model normal behavior with multivariate Gaussian\n",
    "- **Probability Contours**: Visualize confidence regions for normal operation\n",
    "- **Threshold Selection**: Choose optimal detection thresholds\n",
    "- **Industrial Applications**: Apply to temperature-pressure monitoring systems\n",
    "\n",
    "### **Why 2D?**\n",
    "- **Easy Visualization**: See anomalies directly on scatter plots\n",
    "- **Clear Understanding**: Intuitive grasp of normal vs abnormal regions\n",
    "- **Real Applications**: Many industrial processes have 2 key variables\n",
    "\n",
    "### **Dataset**: \n",
    "Industrial Process with 2 sensors:\n",
    "- **Temperature (¬∞C)**: Process operating temperature  \n",
    "- **Pressure (Bar)**: System pressure\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d728c",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll use basic libraries for 2D anomaly detection and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688663b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "%matplotlib widget\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Ready for 2D anomaly detection tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb71f8",
   "metadata": {},
   "source": [
    "## 2. Generate 2D Industrial Dataset\n",
    "\n",
    "Let's create a simple 2D dataset with temperature and pressure measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_industrial_data(n_normal=500, n_anomalies=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate 2D industrial process data:\n",
    "    - Temperature (¬∞C): Process operating temperature\n",
    "    - Pressure (Bar): System pressure\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Normal operation: Temperature ~ 75¬∞C, Pressure ~ 2.5 Bar\n",
    "    normal_mean = np.array([75.0, 2.5])\n",
    "    \n",
    "    # Covariance matrix (temperature and pressure are slightly correlated)\n",
    "    normal_cov = np.array([[9.0, 0.5],   # Temperature variance = 9, correlation with pressure\n",
    "                          [0.5, 2.0]])  # Pressure variance = 0.25\n",
    "    \n",
    "    # Generate normal data\n",
    "    normal_data = np.random.multivariate_normal(normal_mean, normal_cov, n_normal)\n",
    "    \n",
    "    # Generate different types of anomalies\n",
    "    anomalies = []\n",
    "    \n",
    "    # Type 1: High temperature (overheating)\n",
    "    n_hot = n_anomalies // 3\n",
    "    hot_data = np.random.multivariate_normal([90, 2.8], [[4, 0.5], [0.5, 0.16]], n_hot)\n",
    "    anomalies.append(hot_data)\n",
    "    \n",
    "    # Type 2: High pressure (pressure surge)\n",
    "    n_pressure = n_anomalies // 3\n",
    "    pressure_data = np.random.multivariate_normal([77, 7.0], [[4, -0.5], [-0.5, 0.25]], n_pressure)\n",
    "    anomalies.append(pressure_data)\n",
    "    \n",
    "    # Type 3: Low temperature + low pressure (shutdown condition)\n",
    "    n_low = n_anomalies - n_hot - n_pressure\n",
    "    low_data = np.random.multivariate_normal([60, 1.5], [[9, 0.8], [0.8, 0.16]], n_low)\n",
    "    anomalies.append(low_data)\n",
    "    \n",
    "    # Combine all data\n",
    "    if anomalies:\n",
    "        anomaly_data = np.vstack(anomalies)\n",
    "        X = np.vstack([normal_data, anomaly_data])\n",
    "        y = np.hstack([np.zeros(n_normal), np.ones(n_anomalies)])\n",
    "    else:\n",
    "        X = normal_data\n",
    "        y = np.zeros(n_normal)\n",
    "    \n",
    "    # Create labels\n",
    "    labels = ['Normal'] * n_normal\n",
    "    if n_anomalies > 0:\n",
    "        labels.extend(['High_Temp'] * n_hot + ['High_Pressure'] * n_pressure + ['Low_Temp_Pressure'] * n_low)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(X, columns=['Temperature_C', 'Pressure_Bar'])\n",
    "    df['is_anomaly'] = y\n",
    "    df['anomaly_type'] = labels\n",
    "    \n",
    "    return df, X, y\n",
    "\n",
    "# Generate the 2D dataset\n",
    "print(\"Generating 2D Industrial Process Dataset...\")\n",
    "df, X, y = generate_2d_industrial_data(n_normal=500, n_anomalies=50)\n",
    "\n",
    "print(f\"\\nDataset created successfully!\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Normal samples: {(y == 0).sum()}\")\n",
    "print(f\"Anomalous samples: {(y == 1).sum()}\")\n",
    "print(f\"Anomaly rate: {(y == 1).mean()*100:.1f}%\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset statistics:\")\n",
    "display(df[['Temperature_C', 'Pressure_Bar']].describe())\n",
    "\n",
    "print(\"\\nAnomaly type distribution:\")\n",
    "print(df['anomaly_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151ec55",
   "metadata": {},
   "source": [
    "## 3. Visualize the 2D Data\n",
    "\n",
    "Let's plot the 2D data to see the normal operating region and anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive visualization of the 2D data\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(7, 6))\n",
    "\n",
    "# Color map for different anomaly types\n",
    "colors = {'Normal': 'blue', 'High_Temp': 'red', 'High_Pressure': 'orange', 'Low_Temp_Pressure': 'purple'}\n",
    "\n",
    "# 1. Main scatter plot with all data points\n",
    "for anomaly_type in df['anomaly_type'].unique():\n",
    "    mask = df['anomaly_type'] == anomaly_type\n",
    "    data_subset = df[mask]\n",
    "    \n",
    "    alpha = 0.6 if anomaly_type == 'Normal' else 0.8\n",
    "    size = 30 if anomaly_type == 'Normal' else 60\n",
    "    \n",
    "    ax1.scatter(data_subset['Temperature_C'], data_subset['Pressure_Bar'],\n",
    "              c=colors[anomaly_type], label=anomaly_type, \n",
    "              alpha=alpha, s=size, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel('Temperature (¬∞C)')\n",
    "ax1.set_ylabel('Pressure (Bar)')\n",
    "ax1.set_title('2D Industrial Process Data\\nTemperature vs Pressure')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Temperature distribution\n",
    "normal_temp = df[df['is_anomaly'] == 0]['Temperature_C']\n",
    "anomaly_temp = df[df['is_anomaly'] == 1]['Temperature_C']\n",
    "\n",
    "ax2.hist(normal_temp, bins=20, alpha=0.7, label='Normal', color='blue', density=True)\n",
    "ax2.hist(anomaly_temp, bins=15, alpha=0.7, label='Anomalies', color='red', density=True)\n",
    "ax2.set_xlabel('Temperature (¬∞C)')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Temperature Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Pressure distribution\n",
    "normal_pressure = df[df['is_anomaly'] == 0]['Pressure_Bar']\n",
    "anomaly_pressure = df[df['is_anomaly'] == 1]['Pressure_Bar']\n",
    "\n",
    "ax3.hist(normal_pressure, bins=20, alpha=0.7, label='Normal', color='blue', density=True)\n",
    "ax3.hist(anomaly_pressure, bins=15, alpha=0.7, label='Anomalies', color='red', density=True)\n",
    "ax3.set_xlabel('Pressure (Bar)')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Pressure Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Correlation analysis\n",
    "correlation = df[['Temperature_C', 'Pressure_Bar']].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='RdBu_r', center=0,\n",
    "            fmt='.3f', square=True, linewidths=0.5, ax=ax4)\n",
    "ax4.set_title('Temperature-Pressure Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"KEY OBSERVATIONS:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ Normal operation centers around 75¬∞C and 2.5 Bar\")\n",
    "print(\"üî• High temperature anomalies: ~90¬∞C\")\n",
    "print(\"üí® High pressure anomalies: ~4.0 Bar\")\n",
    "print(\"‚ùÑÔ∏è Low temperature-pressure anomalies: ~60¬∞C, 1.5 Bar\")\n",
    "print(f\"üîó Temperature-Pressure correlation: {correlation.iloc[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d77c5a",
   "metadata": {},
   "source": [
    "## 4. Gaussian Multivariate Anomaly Detection\n",
    "\n",
    "Now let's implement the Gaussian multivariate method to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianAnomalyDetector:\n",
    "    \"\"\"\n",
    "    Simple Gaussian Multivariate Anomaly Detector for 2D data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.cov = None\n",
    "        self.distribution = None\n",
    "        \n",
    "    def fit(self, X_normal):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian model to normal data only\n",
    "        \"\"\"\n",
    "        # Calculate mean and covariance matrix from normal data\n",
    "        self.mean = np.mean(X_normal, axis=0)\n",
    "        self.cov = np.cov(X_normal, rowvar=False)\n",
    "        \n",
    "        # Add small regularization to ensure positive definite covariance\n",
    "        reg_param = 1e-6\n",
    "        self.cov += reg_param * np.eye(self.cov.shape[0])\n",
    "        \n",
    "        # Create the multivariate normal distribution\n",
    "        self.distribution = multivariate_normal(mean=self.mean, cov=self.cov)\n",
    "        \n",
    "        print(f\"Gaussian model fitted:\")\n",
    "        print(f\"  Mean: [{self.mean[0]:.2f}, {self.mean[1]:.2f}]\")\n",
    "        print(f\"  Covariance matrix:\")\n",
    "        print(f\"    [[{self.cov[0,0]:.3f}, {self.cov[0,1]:.3f}],\")\n",
    "        print(f\"     [{self.cov[1,0]:.3f}, {self.cov[1,1]:.3f}]]\")\n",
    "    \n",
    "    def get_probabilities(self, X):\n",
    "        \"\"\"\n",
    "        Get probability density values for data points\n",
    "        \"\"\"\n",
    "        return self.distribution.pdf(X)\n",
    "    \n",
    "    def get_anomaly_scores(self, X):\n",
    "        \"\"\"\n",
    "        Get anomaly scores (lower probability = higher anomaly score)\n",
    "        \"\"\"\n",
    "        probabilities = self.get_probabilities(X)\n",
    "        # Use negative log probability as anomaly score\n",
    "        return -np.log(probabilities + 1e-10)  # Add small value to avoid log(0)\n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        \"\"\"\n",
    "        Predict anomalies based on threshold\n",
    "        \"\"\"\n",
    "        anomaly_scores = self.get_anomaly_scores(X)\n",
    "        return (anomaly_scores > threshold).astype(int)\n",
    "\n",
    "# Separate normal data for training (unsupervised approach)\n",
    "X_normal = X[y == 0]  # Only normal data\n",
    "X_test = X  # All data for testing\n",
    "y_test = y  # All labels for testing\n",
    "\n",
    "print(\"DATA PREPARATION:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Training data (normal only): {X_normal.shape[0]} samples\")\n",
    "print(f\"Test data (normal + anomalies): {X_test.shape[0]} samples\")\n",
    "print(f\"Test anomaly rate: {(y_test == 1).mean()*100:.1f}%\")\n",
    "\n",
    "# Train the Gaussian anomaly detector\n",
    "print(\"\\nTRAINING GAUSSIAN ANOMALY DETECTOR:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "detector = GaussianAnomalyDetector()\n",
    "detector.fit(X_normal)\n",
    "\n",
    "# Get anomaly scores for all test data\n",
    "anomaly_scores = detector.get_anomaly_scores(X_test)\n",
    "probabilities = detector.get_probabilities(X_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Model trained successfully!\")\n",
    "print(f\"Anomaly scores range: [{anomaly_scores.min():.3f}, {anomaly_scores.max():.3f}]\")\n",
    "print(f\"Probability range: [{probabilities.min():.6f}, {probabilities.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b553d3d",
   "metadata": {},
   "source": [
    "## 5. Visualize Gaussian Model and Probability Contours\n",
    "\n",
    "Let's visualize the fitted Gaussian model with probability contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of the Gaussian model with contours\n",
    "def plot_gaussian_model(detector, X, y, title=\"Gaussian Anomaly Detection Model\"):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    \n",
    "    # Create a grid for contour plotting\n",
    "    temp_range = np.linspace(X[:, 0].min() - 5, X[:, 0].max() + 5, 100)\n",
    "    pressure_range = np.linspace(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5, 100)\n",
    "    temp_grid, pressure_grid = np.meshgrid(temp_range, pressure_range)\n",
    "    grid_points = np.column_stack([temp_grid.ravel(), pressure_grid.ravel()])\n",
    "    \n",
    "    # Calculate probabilities for the grid\n",
    "    grid_probabilities = detector.get_probabilities(grid_points)\n",
    "    grid_probs_2d = grid_probabilities.reshape(temp_grid.shape)\n",
    "    \n",
    "    # 1. Probability contours with data points\n",
    "    contours = ax1.contour(temp_grid, pressure_grid, grid_probs_2d, \n",
    "                          levels=8, colors='gray', alpha=0.6, linewidths=1)\n",
    "    ax1.clabel(contours, inline=True, fontsize=8, fmt='%.4f')\n",
    "    \n",
    "    # Plot data points\n",
    "    normal_mask = y == 0\n",
    "    anomaly_mask = y == 1\n",
    "    \n",
    "    ax1.scatter(X[normal_mask, 0], X[normal_mask, 1], \n",
    "               c='blue', alpha=0.6, s=30, label='Normal', edgecolors='black', linewidth=0.5)\n",
    "    ax1.scatter(X[anomaly_mask, 0], X[anomaly_mask, 1], \n",
    "               c='red', alpha=0.8, s=60, label='Anomalies', edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    # Mark the center (mean)\n",
    "    ax1.scatter(detector.mean[0], detector.mean[1], \n",
    "               c='green', s=200, marker='X', label='Mean', edgecolors='black', linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Temperature (¬∞C)')\n",
    "    ax1.set_ylabel('Pressure (Bar)')\n",
    "    ax1.set_title('Gaussian Model - Probability Contours')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Anomaly scores heatmap\n",
    "    grid_anomaly_scores = detector.get_anomaly_scores(grid_points)\n",
    "    grid_scores_2d = grid_anomaly_scores.reshape(temp_grid.shape)\n",
    "    \n",
    "    heatmap = ax2.contourf(temp_grid, pressure_grid, grid_scores_2d, \n",
    "                          levels=20, cmap='YlOrRd', alpha=0.8)\n",
    "    fig.colorbar(heatmap, ax=ax2, label='Anomaly Score')\n",
    "    \n",
    "    # Plot data points\n",
    "    ax2.scatter(X[normal_mask, 0], X[normal_mask, 1], \n",
    "               c='blue', alpha=0.8, s=30, label='Normal', edgecolors='white', linewidth=1)\n",
    "    ax2.scatter(X[anomaly_mask, 0], X[anomaly_mask, 1], \n",
    "               c='darkred', alpha=1.0, s=60, label='Anomalies', edgecolors='white', linewidth=1)\n",
    "    \n",
    "    ax2.set_xlabel('Temperature (¬∞C)')\n",
    "    ax2.set_ylabel('Pressure (Bar)')\n",
    "    ax2.set_title('Anomaly Score Heatmap\\n(Higher = More Anomalous)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Anomaly score distributions\n",
    "    normal_scores = anomaly_scores[y == 0]\n",
    "    anomaly_scores_subset = anomaly_scores[y == 1]\n",
    "    \n",
    "    ax3.hist(normal_scores, bins=20, alpha=0.7, label='Normal', color='blue', density=True)\n",
    "    ax3.hist(anomaly_scores_subset, bins=15, alpha=0.7, label='Anomalies', color='red', density=True)\n",
    "    ax3.set_xlabel('Anomaly Score')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.set_title('Anomaly Score Distributions')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Probability distributions\n",
    "    normal_probs = probabilities[y == 0]\n",
    "    anomaly_probs = probabilities[y == 1]\n",
    "    \n",
    "    ax4.hist(normal_probs, bins=20, alpha=0.7, label='Normal', color='blue', density=True)\n",
    "    ax4.hist(anomaly_probs, bins=15, alpha=0.7, label='Anomalies', color='red', density=True)\n",
    "    ax4.set_xlabel('Probability Density')\n",
    "    ax4.set_ylabel('Density')\n",
    "    ax4.set_title('Probability Distributions')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(0, max(probabilities) * 1.1)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the Gaussian model\n",
    "plot_gaussian_model(detector, X_test, y_test)\n",
    "\n",
    "print(\"GAUSSIAN MODEL VISUALIZATION:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"üìä Top-left: Probability contours show confidence regions\")\n",
    "print(\"üî• Top-right: Anomaly score heatmap (red = high anomaly score)\")\n",
    "print(\"üìà Bottom-left: Score distributions (normal vs anomalous)\")\n",
    "print(\"üìâ Bottom-right: Probability distributions\")\n",
    "print(\"\\nüí° Key Insight: Anomalies have low probability and high anomaly scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6dbb57",
   "metadata": {},
   "source": [
    "## 6. Interactive Threshold Explorer\n",
    "\n",
    "Let's create an interactive tool to explore how different thresholds affect anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_2d_threshold_explorer(threshold_percentile=90):\n",
    "    \"\"\"\n",
    "    Interactive exploration of thresholds in 2D space\n",
    "    \"\"\"\n",
    "    # Calculate threshold based on percentile\n",
    "    threshold = np.percentile(anomaly_scores, threshold_percentile)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = detector.predict(X_test, threshold)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    \n",
    "    # 1. 2D scatter plot with decision boundary\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    \n",
    "    # Create grid for decision boundary\n",
    "    temp_range = np.linspace(X_test[:, 0].min() - 3, X_test[:, 0].max() + 3, 150)\n",
    "    pressure_range = np.linspace(X_test[:, 1].min() - 0.3, X_test[:, 1].max() + 0.3, 150)\n",
    "    temp_grid, pressure_grid = np.meshgrid(temp_range, pressure_range)\n",
    "    grid_points = np.column_stack([temp_grid.ravel(), pressure_grid.ravel()])\n",
    "    \n",
    "    # Calculate scores for grid\n",
    "    grid_scores = detector.get_anomaly_scores(grid_points)\n",
    "    grid_scores_2d = grid_scores.reshape(temp_grid.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    decision_boundary = ax1.contour(temp_grid, pressure_grid, grid_scores_2d, \n",
    "                                   levels=[threshold], colors=['black'], linewidths=3)\n",
    "    ax1.clabel(decision_boundary, inline=True, fontsize=10, fmt=f'Threshold: {threshold:.2f}')\n",
    "    \n",
    "    # Plot background regions\n",
    "    ax1.contourf(temp_grid, pressure_grid, grid_scores_2d, \n",
    "                levels=[0, threshold, grid_scores.max()], \n",
    "                colors=['lightblue', 'lightcoral'], alpha=0.3)\n",
    "    \n",
    "    # Plot actual data points with prediction colors\n",
    "    correct_normal = (y_test == 0) & (y_pred == 0)\n",
    "    correct_anomaly = (y_test == 1) & (y_pred == 1)\n",
    "    false_positive = (y_test == 0) & (y_pred == 1)\n",
    "    false_negative = (y_test == 1) & (y_pred == 0)\n",
    "    \n",
    "    ax1.scatter(X_test[correct_normal, 0], X_test[correct_normal, 1], \n",
    "               c='blue', s=40, alpha=0.7, label='True Negative', edgecolors='black', linewidth=0.5)\n",
    "    ax1.scatter(X_test[correct_anomaly, 0], X_test[correct_anomaly, 1], \n",
    "               c='red', s=60, alpha=0.9, label='True Positive', edgecolors='black', linewidth=0.5)\n",
    "    ax1.scatter(X_test[false_positive, 0], X_test[false_positive, 1], \n",
    "               c='orange', s=80, alpha=0.9, label='False Positive', marker='^', edgecolors='black', linewidth=1)\n",
    "    ax1.scatter(X_test[false_negative, 0], X_test[false_negative, 1], \n",
    "               c='purple', s=80, alpha=0.9, label='False Negative', marker='s', edgecolors='black', linewidth=1)\n",
    "    \n",
    "    ax1.set_xlabel('Temperature (¬∞C)')\n",
    "    ax1.set_ylabel('Pressure (Bar)')\n",
    "    ax1.set_title(f'2D Decision Boundary\\nThreshold: {threshold:.3f} ({threshold_percentile}th percentile)')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Confusion Matrix\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "               xticklabels=['Normal', 'Anomaly'],\n",
    "               yticklabels=['Normal', 'Anomaly'])\n",
    "    ax2.set_title(f'Confusion Matrix')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_ylabel('Actual')\n",
    "    \n",
    "    # 3. Metrics bar chart\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "    values = [precision, recall, f1]\n",
    "    colors_metrics = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "    \n",
    "    bars = ax3.bar(metrics, values, color=colors_metrics, edgecolor='black', linewidth=1)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    ax3.set_title('Performance Metrics')\n",
    "    ax3.set_ylabel('Score')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 4. Anomaly score distribution with threshold\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    normal_scores = anomaly_scores[y_test == 0]\n",
    "    anomaly_scores_subset = anomaly_scores[y_test == 1]\n",
    "    \n",
    "    ax4.hist(normal_scores, bins=25, alpha=0.7, label='Normal', color='blue', density=True)\n",
    "    ax4.hist(anomaly_scores_subset, bins=15, alpha=0.7, label='Anomalies', color='red', density=True)\n",
    "    ax4.axvline(threshold, color='black', linestyle='--', linewidth=3, \n",
    "               label=f'Threshold: {threshold:.3f}')\n",
    "    ax4.set_xlabel('Anomaly Score')\n",
    "    ax4.set_ylabel('Density')\n",
    "    ax4.set_title('Score Distribution with Threshold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Prediction breakdown pie chart\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        breakdown_labels = ['True Negative\\n(Normal‚ÜíNormal)', 'False Positive\\n(Normal‚ÜíAnomaly)', \n",
    "                           'False Negative\\n(Anomaly‚ÜíNormal)', 'True Positive\\n(Anomaly‚ÜíAnomaly)']\n",
    "        breakdown_values = [tn, fp, fn, tp]\n",
    "        breakdown_colors = ['lightblue', 'orange', 'purple', 'lightcoral']\n",
    "        \n",
    "        wedges, texts, autotexts = ax5.pie(breakdown_values, labels=breakdown_labels, \n",
    "                                          colors=breakdown_colors, autopct='%1.0f', \n",
    "                                          startangle=90, textprops={'fontsize': 9})\n",
    "        ax5.set_title('Prediction Breakdown')\n",
    "    \n",
    "    # 6. Statistics summary\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Create statistics text\n",
    "    stats_text = f\"\"\"\n",
    "    DETECTION STATISTICS\n",
    "    {'='*30}\n",
    "    \n",
    "    Threshold: {threshold:.4f}\n",
    "    Percentile: {threshold_percentile}th\n",
    "    \n",
    "    Total Samples: {len(y_test)}\n",
    "    Predicted Anomalies: {np.sum(y_pred)}\n",
    "    Actual Anomalies: {np.sum(y_test)}\n",
    "    \n",
    "    PERFORMANCE METRICS:\n",
    "    Precision: {precision:.3f}\n",
    "    Recall: {recall:.3f}\n",
    "    F1-Score: {f1:.3f}\n",
    "    \"\"\"\n",
    "    \n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        stats_text += f\"\"\"\n",
    "    \n",
    "    CONFUSION MATRIX:\n",
    "    True Negatives: {tn}\n",
    "    False Positives: {fp}\n",
    "    False Negatives: {fn}\n",
    "    True Positives: {tp}\n",
    "    \n",
    "    False Positive Rate: {fpr:.3f}\n",
    "        \"\"\"\n",
    "    \n",
    "    ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=11,\n",
    "            verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f'2D Gaussian Anomaly Detection - Interactive Analysis\\n'\n",
    "                f'Threshold Percentile: {threshold_percentile}%', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create the interactive widget\n",
    "print(\"üéÆ INTERACTIVE 2D THRESHOLD EXPLORER\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Adjust the threshold percentile to see how it affects anomaly detection!\")\n",
    "print(\"Higher percentile = stricter detection (fewer false positives)\")\n",
    "print(\"Lower percentile = more sensitive detection (fewer false negatives)\")\n",
    "print()\n",
    "\n",
    "interact(interactive_2d_threshold_explorer,\n",
    "         threshold_percentile=widgets.IntSlider(\n",
    "             value=90,\n",
    "             min=70,\n",
    "             max=99,\n",
    "             step=1,\n",
    "             description='Threshold %:',\n",
    "             style={'description_width': 'initial'}\n",
    "         ));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621fad74",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis\n",
    "\n",
    "Let's analyze the performance across different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance across different thresholds\n",
    "percentiles = np.arange(70, 100, 2)  # From 70% to 99%\n",
    "thresholds = [np.percentile(anomaly_scores, p) for p in percentiles]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, (percentile, threshold) in enumerate(zip(percentiles, thresholds)):\n",
    "    y_pred = detector.predict(X_test, threshold)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    else:\n",
    "        if np.all(y_pred == 0):\n",
    "            tn, fp, fn, tp = np.sum(y_test == 0), 0, np.sum(y_test == 1), 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = 0, np.sum(y_test == 0), 0, np.sum(y_test == 1)\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'percentile': percentile,\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'fpr': fpr,\n",
    "        'n_predicted_anomalies': np.sum(y_pred),\n",
    "        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find optimal threshold\n",
    "best_f1_idx = results_df['f1_score'].idxmax()\n",
    "optimal_result = results_df.iloc[best_f1_idx]\n",
    "\n",
    "print(\"PERFORMANCE ANALYSIS ACROSS THRESHOLDS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best F1-Score: {optimal_result['f1_score']:.3f}\")\n",
    "print(f\"Optimal Threshold: {optimal_result['threshold']:.3f} ({optimal_result['percentile']:.0f}th percentile)\")\n",
    "print(f\"At optimal threshold:\")\n",
    "print(f\"  Precision: {optimal_result['precision']:.3f}\")\n",
    "print(f\"  Recall: {optimal_result['recall']:.3f}\")\n",
    "print(f\"  False Positive Rate: {optimal_result['fpr']:.3f}\")\n",
    "\n",
    "# Plot performance curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(7, 5))\n",
    "\n",
    "# 1. Metrics vs Percentile\n",
    "ax1.plot(results_df['percentile'], results_df['precision'], 'b-', linewidth=2, label='Precision')\n",
    "ax1.plot(results_df['percentile'], results_df['recall'], 'r-', linewidth=2, label='Recall')\n",
    "ax1.plot(results_df['percentile'], results_df['f1_score'], 'g-', linewidth=2, label='F1-Score')\n",
    "ax1.axvline(optimal_result['percentile'], color='purple', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimal ({optimal_result[\"percentile\"]:.0f}%)')\n",
    "ax1.set_xlabel('Threshold Percentile')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Performance Metrics vs Threshold Percentile')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# 2. ROC-like curve (TPR vs FPR)\n",
    "tpr = results_df['recall']  # True Positive Rate = Recall\n",
    "fpr_vals = results_df['fpr']  # False Positive Rate\n",
    "\n",
    "ax2.plot(fpr_vals, tpr, 'bo-', linewidth=2, markersize=4)\n",
    "ax2.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
    "ax2.scatter(optimal_result['fpr'], optimal_result['recall'], \n",
    "           c='red', s=100, marker='*', label=f'Optimal (F1={optimal_result[\"f1_score\"]:.3f})')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate (Recall)')\n",
    "ax2.set_title('ROC-like Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# 3. Number of detected anomalies\n",
    "ax3.plot(results_df['percentile'], results_df['n_predicted_anomalies'], 'purple', linewidth=2)\n",
    "ax3.axhline(y=50, color='red', linestyle='--', alpha=0.7, label='True Anomalies (50)')\n",
    "ax3.axvline(optimal_result['percentile'], color='purple', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimal ({optimal_result[\"percentile\"]:.0f}%)')\n",
    "ax3.set_xlabel('Threshold Percentile')\n",
    "ax3.set_ylabel('Number of Predicted Anomalies')\n",
    "ax3.set_title('Detection Count vs Threshold Percentile')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Threshold values\n",
    "ax4.plot(results_df['percentile'], results_df['threshold'], 'orange', linewidth=2)\n",
    "ax4.axvline(optimal_result['percentile'], color='purple', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimal ({optimal_result[\"percentile\"]:.0f}%)')\n",
    "ax4.set_xlabel('Threshold Percentile')\n",
    "ax4.set_ylabel('Threshold Value (Anomaly Score)')\n",
    "ax4.set_title('Threshold Value vs Percentile')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('2D Gaussian Anomaly Detection - Performance Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show top 5 results\n",
    "print(\"\\nTOP 5 PERFORMANCE RESULTS (by F1-Score):\")\n",
    "top_results = results_df.nlargest(5, 'f1_score')[['percentile', 'threshold', 'precision', 'recall', 'f1_score', 'fpr']]\n",
    "display(top_results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ea5f8",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways - 2D Gaussian Anomaly Detection\n",
    "\n",
    "### **What We Learned:**\n",
    "\n",
    "#### **1. Gaussian Multivariate Method:**\n",
    "- **Simple & Effective**: Models normal behavior with mean and covariance\n",
    "- **Probabilistic**: Provides probability estimates for each data point\n",
    "- **Interpretable**: Easy to understand decision boundaries\n",
    "\n",
    "#### **2. 2D Visualization Benefits:**\n",
    "- **Clear Decision Boundary**: See exactly where normal ends and anomaly begins\n",
    "- **Confidence Contours**: Probability levels show certainty regions\n",
    "- **Error Analysis**: Visually identify false positives and false negatives\n",
    "\n",
    "#### **3. Threshold Selection Strategy:**\n",
    "- **High Percentile (95-99%)**: Conservative - few false alarms, might miss subtle anomalies\n",
    "- **Medium Percentile (85-90%)**: Balanced - good trade-off for most applications\n",
    "- **Low Percentile (70-80%)**: Sensitive - catches everything but more false alarms\n",
    "\n",
    "### **Industrial Applications:**\n",
    "\n",
    "#### **üè≠ Process Monitoring:**\n",
    "- **Temperature-Pressure Systems**: Boiler monitoring, reactor control\n",
    "- **Flow-Pressure Systems**: Pipeline monitoring, pump performance\n",
    "- **Voltage-Current Systems**: Electrical equipment monitoring\n",
    "\n",
    "#### **‚öôÔ∏è Equipment Health:**\n",
    "- **Vibration-Temperature**: Motor and bearing condition monitoring\n",
    "- **Speed-Load**: Machine performance optimization\n",
    "- **Efficiency-Output**: Production quality control\n",
    "\n",
    "### **Method Advantages:**\n",
    "- ‚úÖ **Fast Training**: Only needs to calculate mean and covariance\n",
    "- ‚úÖ **Real-time Detection**: Quick probability calculations\n",
    "- ‚úÖ **No Parameter Tuning**: Minimal hyperparameters to adjust\n",
    "- ‚úÖ **Probabilistic Output**: Confidence levels for decisions\n",
    "- ‚úÖ **Easy Interpretation**: Clear statistical meaning\n",
    "\n",
    "### **Method Limitations:**\n",
    "- ‚ùå **Gaussian Assumption**: Normal data must be roughly Gaussian\n",
    "- ‚ùå **Linear Decision Boundary**: Can't handle complex, non-linear anomaly patterns\n",
    "- ‚ùå **Sensitive to Outliers**: Outliers in training data affect the model\n",
    "- ‚ùå **Single Mode**: Assumes normal data has one main cluster\n",
    "\n",
    "### **Best Practices:**\n",
    "1. **Data Quality**: Ensure training data is truly \"normal\" operation\n",
    "2. **Threshold Tuning**: Use validation data to find optimal threshold\n",
    "3. **Regular Updates**: Retrain model as normal operation evolves\n",
    "4. **Visual Inspection**: Always plot data to verify Gaussian assumption\n",
    "5. **Domain Knowledge**: Use industrial expertise to validate anomaly types\n",
    "\n",
    "### **When to Use Gaussian Method:**\n",
    "- üìä Data approximately follows Gaussian distribution\n",
    "- üéØ Need simple, interpretable model\n",
    "- ‚ö° Require fast real-time detection\n",
    "- üîß Limited computational resources\n",
    "- üë• Need to explain results to operators\n",
    "\n",
    "---\n",
    "\n",
    "**This simplified 2D tutorial provides a solid foundation for understanding anomaly detection principles before moving to more complex, high-dimensional industrial datasets.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
