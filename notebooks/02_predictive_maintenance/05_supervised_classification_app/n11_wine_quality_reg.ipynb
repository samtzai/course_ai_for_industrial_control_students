{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f806abc0",
   "metadata": {},
   "source": [
    "# üç∑ Wine Quality Regression Tutorial\n",
    "\n",
    "## **Industrial Quality Control with Continuous Scoring**\n",
    "\n",
    "### **Main Goal:**\n",
    "Learn to predict wine quality as continuous scores using regression techniques, demonstrating how machine learning can provide precise, nuanced quality assessments for industrial quality control processes.\n",
    "\n",
    "### **Key Learning Objectives:**\n",
    "- **Continuous Quality Assessment**: Predict precise quality scores (not just discrete grades)\n",
    "- **Regression Modeling**: Apply neural networks and classical algorithms for regression\n",
    "- **Uncertainty Quantification**: Provide confidence intervals for quality predictions\n",
    "- **Industrial Applications**: Apply to manufacturing processes requiring precise measurements\n",
    "- **Performance Optimization**: Handle regression-specific challenges and metrics\n",
    "\n",
    "### **Industrial Relevance:**\n",
    "Apply to **precise quality scoring**, **process control optimization**, **continuous monitoring systems**, and **quality assurance** where exact measurements matter more than categories.\n",
    "\n",
    "### **Interactive Features:**\n",
    "üéÆ Multi-model regression comparison | üìä Residual analysis | ‚ö° Prediction intervals | üî¨ Uncertainty estimation\n",
    "\n",
    "**Dataset**: Wine Quality Dataset with 11 physicochemical features predicting continuous quality scores\n",
    "\n",
    "**Regression vs Classification:**\n",
    "- **Classification**: Discrete quality grades (3, 4, 5, 6, 7, 8, 9)\n",
    "- **Regression**: Continuous quality scores (3.2, 5.7, 6.8, 7.3, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c99ac",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll use comprehensive ML libraries for this regression tutorial, including PyTorch for neural networks and scikit-learn for traditional regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb841533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "%matplotlib widget\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Available for regression: Neural Networks, Random Forest, Linear Models, SVR{',' + ' XGBoost' if XGBOOST_AVAILABLE else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084fbe5",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Wine Quality Dataset\n",
    "\n",
    "Let's load the wine quality dataset and treat quality as a continuous variable for regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic wine quality dataset for regression\n",
    "np.random.seed(42)\n",
    "n_samples = 1200\n",
    "\n",
    "# Generate synthetic wine quality data with continuous scores\n",
    "def generate_wine_regression_data(n_samples):\n",
    "    \"\"\"Generate realistic wine data with continuous quality scores\"\"\"\n",
    "    \n",
    "    # Create realistic wine chemistry features\n",
    "    fixed_acidity = np.random.normal(8.0, 1.5, n_samples)\n",
    "    volatile_acidity = np.random.normal(0.5, 0.2, n_samples)\n",
    "    citric_acid = np.random.normal(0.25, 0.15, n_samples)\n",
    "    residual_sugar = np.random.lognormal(1.5, 1.0, n_samples)\n",
    "    chlorides = np.random.normal(0.08, 0.03, n_samples)\n",
    "    free_sulfur_dioxide = np.random.normal(30, 15, n_samples)\n",
    "    total_sulfur_dioxide = np.random.normal(120, 40, n_samples)\n",
    "    density = np.random.normal(0.996, 0.002, n_samples)\n",
    "    pH = np.random.normal(3.2, 0.15, n_samples)\n",
    "    sulphates = np.random.normal(0.65, 0.15, n_samples)\n",
    "    alcohol = np.random.normal(10.5, 1.2, n_samples)\n",
    "    \n",
    "    # Create CONTINUOUS quality score based on realistic relationships\n",
    "    quality_score = (\n",
    "        2.0 * (alcohol - 8) / 4 +              # Higher alcohol tends to increase quality\n",
    "        -5.0 * (volatile_acidity - 0.3) +      # Lower volatile acidity is better\n",
    "        2.0 * (citric_acid - 0.1) / 0.3 +      # More citric acid is good\n",
    "        -3.0 * np.abs(pH - 3.3) / 0.5 +        # pH around 3.3 is optimal\n",
    "        1.5 * (sulphates - 0.4) / 0.4 +        # More sulphates help\n",
    "        -0.5 * np.abs(density - 0.996) * 1000 + # Density close to 0.996 is better\n",
    "        np.random.normal(0, 0.4, n_samples)     # Add noise for realism\n",
    "    )\n",
    "    \n",
    "    # Convert to continuous quality ratings (3.0-9.0 scale with decimals)\n",
    "    quality = np.clip(quality_score + 6.0, 3.0, 9.0)\n",
    "    \n",
    "    # Add small random variations to make it truly continuous\n",
    "    quality += np.random.normal(0, 0.1, n_samples)\n",
    "    quality = np.clip(quality, 3.0, 9.0)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'fixed_acidity': fixed_acidity,\n",
    "        'volatile_acidity': volatile_acidity,\n",
    "        'citric_acid': citric_acid,\n",
    "        'residual_sugar': residual_sugar,\n",
    "        'chlorides': chlorides,\n",
    "        'free_sulfur_dioxide': free_sulfur_dioxide,\n",
    "        'total_sulfur_dioxide': total_sulfur_dioxide,\n",
    "        'density': density,\n",
    "        'pH': pH,\n",
    "        'sulphates': sulphates,\n",
    "        'alcohol': alcohol,\n",
    "        'quality': quality\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate the dataset\n",
    "df = generate_wine_regression_data(n_samples)\n",
    "\n",
    "print(\"Wine Quality Regression Dataset Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {df.columns.tolist()[:-1]}\")\n",
    "print(f\"Target: {df.columns[-1]} (continuous)\")\n",
    "print(f\"Quality range: {df['quality'].min():.2f} - {df['quality'].max():.2f}\")\n",
    "print(f\"Quality mean: {df['quality'].mean():.2f} ¬± {df['quality'].std():.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"First 10 quality scores (showing continuous values):\")\n",
    "print(df['quality'].head(10).round(2).tolist())\n",
    "print()\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Visualize continuous quality distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "# Histogram of continuous quality scores\n",
    "ax1.hist(df['quality'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax1.set_xlabel('Quality Score (Continuous)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Continuous Quality Scores')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvline(df['quality'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"quality\"].mean():.2f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot showing quality distribution\n",
    "ax2.boxplot(df['quality'], vert=True, patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "ax2.set_ylabel('Quality Score')\n",
    "ax2.set_title('Quality Score Distribution (Box Plot)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticklabels(['Wine Quality'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRegression vs Classification:\")\n",
    "print(f\"Continuous scores allow for more precise predictions:\")\n",
    "print(f\"Instead of: 'Quality = 6' (classification)\")\n",
    "print(f\"We predict: 'Quality = 6.23' (regression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dabe97",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing for Regression\n",
    "\n",
    "Prepare the data for regression models by scaling features and handling the continuous target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1860a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for regression\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']  # Keep as continuous values (no encoding needed)\n",
    "\n",
    "print(\"Regression Data Preparation\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target type: Continuous values (no encoding needed)\")\n",
    "print(f\"Target range: {y.min():.2f} to {y.max():.2f}\")\n",
    "print()\n",
    "\n",
    "# Feature correlation analysis\n",
    "correlation_matrix = df.corr()\n",
    "quality_correlations = correlation_matrix['quality'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Features most correlated with quality (for regression):\")\n",
    "print(\"-\" * 50)\n",
    "for feature, corr in quality_correlations.items():\n",
    "    if feature != 'quality':\n",
    "        print(f\"{feature:<25}: {corr:>7.4f}\")\n",
    "print()\n",
    "\n",
    "# Split the data (no stratification needed for regression)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# For neural networks, we can also scale the target (optional)\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Convert to PyTorch tensors for neural network\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train_scaled).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test_scaled).to(device)\n",
    "\n",
    "print(f\"Data splits:\")\n",
    "print(f\"Training set: {X_train_tensor.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_tensor.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train_tensor.shape[1]}\")\n",
    "print()\n",
    "\n",
    "# Target statistics\n",
    "print(f\"Target statistics (original scale):\")\n",
    "print(f\"Training - Mean: {y_train.mean():.3f}, Std: {y_train.std():.3f}\")\n",
    "print(f\"Test     - Mean: {y_test.mean():.3f}, Std: {y_test.std():.3f}\")\n",
    "print()\n",
    "\n",
    "print(f\"Target statistics (scaled for neural network):\")\n",
    "print(f\"Training - Mean: {y_train_scaled.mean():.3f}, Std: {y_train_scaled.std():.3f}\")\n",
    "print(f\"Test     - Mean: {y_test_scaled.mean():.3f}, Std: {y_test_scaled.std():.3f}\")\n",
    "\n",
    "# Visualize feature correlations\n",
    "plt.figure(figsize=(6, 5))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix (Regression Analysis)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd125a80",
   "metadata": {},
   "source": [
    "## 4. Define Neural Network for Regression\n",
    "\n",
    "Create a neural network architecture optimized for regression with appropriate activation functions and output layers for continuous predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineQualityRegressor(nn.Module):\n",
    "    \"\"\"Neural Network for Wine Quality Regression\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=11, hidden_sizes=[128, 64, 32], dropout_rate=0.2):\n",
    "        super(WineQualityRegressor, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Hidden layers with batch normalization and dropout\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer for regression (no activation - linear output)\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize network weights\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()  # Remove extra dimension\n",
    "    \n",
    "    def predict_with_uncertainty(self, x, num_samples=100):\n",
    "        \"\"\"Predict with uncertainty estimation using dropout at inference\"\"\"\n",
    "        self.train()  # Enable dropout for uncertainty\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(num_samples):\n",
    "                pred = self.forward(x)\n",
    "                predictions.append(pred.cpu().numpy())\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        mean_pred = np.mean(predictions, axis=0)\n",
    "        std_pred = np.std(predictions, axis=0)\n",
    "        \n",
    "        return mean_pred, std_pred\n",
    "\n",
    "# Create the regression model\n",
    "wine_regressor = WineQualityRegressor(\n",
    "    input_size=X_train_tensor.shape[1],\n",
    "    hidden_sizes=[128, 64, 32, 16],\n",
    "    dropout_rate=0.2\n",
    ").to(device)\n",
    "\n",
    "print(\"Wine Quality Regression Neural Network\")\n",
    "print(\"=\" * 60)\n",
    "print(wine_regressor)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in wine_regressor.parameters())}\")\n",
    "print(f\"Model type: Regression (continuous output)\")\n",
    "print(f\"Output: Single continuous value (quality score)\")\n",
    "print(f\"Loss function: MSE (Mean Squared Error)\")\n",
    "print()\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_input = X_train_tensor[:5]\n",
    "    test_output = wine_regressor(test_input)\n",
    "    print(f\"Test forward pass:\")\n",
    "    print(f\"Input shape: {test_input.shape}\")\n",
    "    print(f\"Output shape: {test_output.shape}\")\n",
    "    print(f\"Sample predictions: {test_output.cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3a431",
   "metadata": {},
   "source": [
    "## 5. Training Function for Regression\n",
    "\n",
    "Implement training loop using regression loss functions (MSE, MAE) with proper optimization techniques for continuous target prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbb039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wine_regressor(model, X_train, y_train, X_test, y_test, \n",
    "                        lr=0.001, epochs=400, print_every=100):\n",
    "    \"\"\"Train the wine quality regression model\"\"\"\n",
    "    \n",
    "    # Regression loss function\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=25, factor=0.5)\n",
    "    \n",
    "    # Tracking metrics\n",
    "    train_losses, test_losses = [], []\n",
    "    train_maes, test_maes = [], []  # Mean Absolute Error\n",
    "    train_r2s, test_r2s = [], []    # R¬≤ scores\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    \n",
    "    print(\"Training Wine Quality Regressor...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        train_outputs = model(X_train)\n",
    "        train_loss = criterion(train_outputs, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        with torch.no_grad():\n",
    "            train_mae = torch.mean(torch.abs(train_outputs - y_train))\n",
    "            \n",
    "            # R¬≤ calculation (coefficient of determination)\n",
    "            train_ss_res = torch.sum((y_train - train_outputs) ** 2)\n",
    "            train_ss_tot = torch.sum((y_train - torch.mean(y_train)) ** 2)\n",
    "            train_r2 = 1 - (train_ss_res / train_ss_tot)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "            test_mae = torch.mean(torch.abs(test_outputs - y_test))\n",
    "            \n",
    "            # R¬≤ for test set\n",
    "            test_ss_res = torch.sum((y_test - test_outputs) ** 2)\n",
    "            test_ss_tot = torch.sum((y_test - torch.mean(y_test)) ** 2)\n",
    "            test_r2 = 1 - (test_ss_res / test_ss_tot)\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        train_maes.append(train_mae.item())\n",
    "        test_maes.append(test_mae.item())\n",
    "        train_r2s.append(train_r2.item())\n",
    "        test_r2s.append(test_r2.item())\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            torch.save(model.state_dict(), 'best_wine_regressor.pth')\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            print(f'Train Loss (MSE): {train_loss.item():.6f}, Train MAE: {train_mae.item():.4f}, Train R¬≤: {train_r2.item():.4f}')\n",
    "            print(f'Test Loss (MSE):  {test_loss.item():.6f}, Test MAE:  {test_mae.item():.4f}, Test R¬≤:  {test_r2.item():.4f}')\n",
    "            print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "            print('-' * 60)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_wine_regressor.pth'))\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_maes': train_maes,\n",
    "        'test_maes': test_maes,\n",
    "        'train_r2s': train_r2s,\n",
    "        'test_r2s': test_r2s\n",
    "    }\n",
    "\n",
    "# Train the model\n",
    "training_results = train_wine_regressor(\n",
    "    wine_regressor, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,\n",
    "    lr=0.001, epochs=400, print_every=100\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed! Best model saved.\")\n",
    "\n",
    "# Convert predictions back to original scale for interpretation\n",
    "wine_regressor.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred_scaled = wine_regressor(X_train_tensor)\n",
    "    test_pred_scaled = wine_regressor(X_test_tensor)\n",
    "\n",
    "# Inverse transform predictions\n",
    "train_pred_original = scaler_y.inverse_transform(train_pred_scaled.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "test_pred_original = scaler_y.inverse_transform(test_pred_scaled.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"\\nFinal Performance (Original Scale):\")\n",
    "print(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, train_pred_original)):.4f}\")\n",
    "print(f\"Test RMSE:  {np.sqrt(mean_squared_error(y_test, test_pred_original)):.4f}\")\n",
    "print(f\"Train MAE:  {mean_absolute_error(y_train, train_pred_original):.4f}\")\n",
    "print(f\"Test MAE:   {mean_absolute_error(y_test, test_pred_original):.4f}\")\n",
    "print(f\"Train R¬≤:   {r2_score(y_train, train_pred_original):.4f}\")\n",
    "print(f\"Test R¬≤:    {r2_score(y_test, test_pred_original):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d934d",
   "metadata": {},
   "source": [
    "## 6. Model Performance Analysis\n",
    "\n",
    "Analyze training progress and model performance using regression-specific visualizations including prediction vs actual plots and residual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance analysis for regression\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Training curves - Loss (MSE)\n",
    "axes[0,0].plot(training_results['train_losses'], label='Train Loss', color='blue', linewidth=2)\n",
    "axes[0,0].plot(training_results['test_losses'], label='Test Loss', color='red', linewidth=2)\n",
    "axes[0,0].set_xlabel('Epoch')\n",
    "axes[0,0].set_ylabel('MSE Loss')\n",
    "axes[0,0].set_title('Training and Test Loss (MSE)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Training curves - MAE\n",
    "axes[0,1].plot(training_results['train_maes'], label='Train MAE', color='blue', linewidth=2)\n",
    "axes[0,1].plot(training_results['test_maes'], label='Test MAE', color='red', linewidth=2)\n",
    "axes[0,1].set_xlabel('Epoch')\n",
    "axes[0,1].set_ylabel('Mean Absolute Error')\n",
    "axes[0,1].set_title('Training and Test MAE')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Training curves - R¬≤\n",
    "axes[0,2].plot(training_results['train_r2s'], label='Train R¬≤', color='blue', linewidth=2)\n",
    "axes[0,2].plot(training_results['test_r2s'], label='Test R¬≤', color='red', linewidth=2)\n",
    "axes[0,2].set_xlabel('Epoch')\n",
    "axes[0,2].set_ylabel('R¬≤ Score')\n",
    "axes[0,2].set_title('Training and Test R¬≤ Score')\n",
    "axes[0,2].legend()\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction vs Actual (Test Set)\n",
    "min_qual = min(y_test.min(), test_pred_original.min()) - 0.2\n",
    "max_qual = max(y_test.max(), test_pred_original.max()) + 0.2\n",
    "\n",
    "axes[1,0].scatter(y_test, test_pred_original, alpha=0.6, color='blue', s=30)\n",
    "axes[1,0].plot([min_qual, max_qual], [min_qual, max_qual], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1,0].set_xlabel('Actual Quality')\n",
    "axes[1,0].set_ylabel('Predicted Quality')\n",
    "axes[1,0].set_title('Prediction vs Actual (Test Set)')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].set_xlim(min_qual, max_qual)\n",
    "axes[1,0].set_ylim(min_qual, max_qual)\n",
    "\n",
    "# Add correlation coefficient\n",
    "corr_coef = np.corrcoef(y_test, test_pred_original)[0,1]\n",
    "axes[1,0].text(0.05, 0.95, f'Correlation: {corr_coef:.3f}', transform=axes[1,0].transAxes, \n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 5. Residual Analysis\n",
    "residuals = y_test - test_pred_original\n",
    "axes[1,1].scatter(test_pred_original, residuals, alpha=0.6, color='green', s=30)\n",
    "axes[1,1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1,1].set_xlabel('Predicted Quality')\n",
    "axes[1,1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[1,1].set_title('Residual Plot (Test Set)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add residual statistics\n",
    "residual_std = np.std(residuals)\n",
    "axes[1,1].text(0.05, 0.95, f'Residual Std: {residual_std:.3f}', transform=axes[1,1].transAxes,\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 6. Residual Distribution\n",
    "axes[1,2].hist(residuals, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[1,2].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1,2].set_xlabel('Residuals')\n",
    "axes[1,2].set_ylabel('Frequency')\n",
    "axes[1,2].set_title('Distribution of Residuals')\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add normality information\n",
    "shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "axes[1,2].text(0.05, 0.95, f'Normal?: p={shapiro_p:.3f}', transform=axes[1,2].transAxes,\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed regression analysis\n",
    "print(\"COMPREHENSIVE REGRESSION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Basic metrics\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_pred_original))\n",
    "test_mae = mean_absolute_error(y_test, test_pred_original)\n",
    "test_r2 = r2_score(y_test, test_pred_original)\n",
    "\n",
    "print(f\"üìä PERFORMANCE METRICS (Test Set):\")\n",
    "print(f\"  Root Mean Square Error (RMSE): {test_rmse:.4f}\")\n",
    "print(f\"  Mean Absolute Error (MAE):     {test_mae:.4f}\")\n",
    "print(f\"  R¬≤ Score (Coefficient of Det): {test_r2:.4f}\")\n",
    "print(f\"  Correlation Coefficient:       {corr_coef:.4f}\")\n",
    "print()\n",
    "\n",
    "# Error analysis\n",
    "abs_errors = np.abs(residuals)\n",
    "print(f\"üéØ PREDICTION ACCURACY ANALYSIS:\")\n",
    "print(f\"  Mean Absolute Residual:        {np.mean(abs_errors):.4f}\")\n",
    "print(f\"  Std of Residuals:              {np.std(residuals):.4f}\")\n",
    "print(f\"  95% of predictions within:     ¬±{1.96 * np.std(residuals):.4f} quality points\")\n",
    "print(f\"  Max prediction error:          {np.max(abs_errors):.4f}\")\n",
    "print(f\"  % predictions within ¬±0.5:     {(abs_errors <= 0.5).mean()*100:.1f}%\")\n",
    "print(f\"  % predictions within ¬±0.3:     {(abs_errors <= 0.3).mean()*100:.1f}%\")\n",
    "print(f\"  % predictions within ¬±0.1:     {(abs_errors <= 0.1).mean()*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Quality range analysis\n",
    "print(f\"üìè PREDICTION RANGE ANALYSIS:\")\n",
    "print(f\"  Actual quality range:          {y_test.min():.2f} - {y_test.max():.2f}\")\n",
    "print(f\"  Predicted quality range:       {test_pred_original.min():.2f} - {test_pred_original.max():.2f}\")\n",
    "print(f\"  Mean actual quality:           {y_test.mean():.3f}\")\n",
    "print(f\"  Mean predicted quality:        {test_pred_original.mean():.3f}\")\n",
    "print()\n",
    "\n",
    "# Model confidence analysis with uncertainty\n",
    "print(f\"üîç UNCERTAINTY ANALYSIS:\")\n",
    "# Use dropout-based uncertainty estimation\n",
    "test_mean_pred, test_std_pred = wine_regressor.predict_with_uncertainty(X_test_tensor, num_samples=50)\n",
    "test_mean_pred_original = scaler_y.inverse_transform(test_mean_pred.reshape(-1, 1)).flatten()\n",
    "test_std_pred_original = test_std_pred * scaler_y.scale_[0]  # Scale standard deviation\n",
    "\n",
    "print(f\"  Average prediction uncertainty: {np.mean(test_std_pred_original):.3f}\")\n",
    "print(f\"  Max prediction uncertainty:     {np.max(test_std_pred_original):.3f}\")\n",
    "print(f\"  Min prediction uncertainty:     {np.min(test_std_pred_original):.3f}\")\n",
    "print()\n",
    "\n",
    "# Industrial quality control interpretation\n",
    "print(f\"üè≠ INDUSTRIAL QUALITY CONTROL INTERPRETATION:\")\n",
    "if test_mae <= 0.2:\n",
    "    print(\"  ‚úÖ EXCELLENT: Very precise quality predictions suitable for high-precision applications\")\n",
    "elif test_mae <= 0.4:\n",
    "    print(\"  ‚úÖ GOOD: Reliable quality predictions suitable for most industrial applications\")\n",
    "elif test_mae <= 0.6:\n",
    "    print(\"  ‚ö†Ô∏è  ACCEPTABLE: Moderate precision, suitable for general quality control\")\n",
    "else:\n",
    "    print(\"  ‚ùå POOR: Low precision, requires improvement for industrial use\")\n",
    "\n",
    "if test_r2 >= 0.8:\n",
    "    print(f\"  ‚úÖ STRONG: Model explains {test_r2*100:.1f}% of quality variance\")\n",
    "elif test_r2 >= 0.6:\n",
    "    print(f\"  ‚úÖ MODERATE: Model explains {test_r2*100:.1f}% of quality variance\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  WEAK: Model explains only {test_r2*100:.1f}% of quality variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafec25",
   "metadata": {},
   "source": [
    "## 7. Regression Metrics Evaluation\n",
    "\n",
    "Evaluate model performance using regression metrics such as MSE, MAE, R¬≤, and RMSE, with quality control specific interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed regression metrics with visualization\n",
    "def evaluate_regression_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Comprehensive evaluation of regression model\"\"\"\n",
    "    \n",
    "    # Basic regression metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Additional metrics\n",
    "    residuals = y_true - y_pred\n",
    "    residual_std = np.std(residuals)\n",
    "    mean_residual = np.mean(residuals)\n",
    "    \n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    # Explained Variance Score\n",
    "    from sklearn.metrics import explained_variance_score\n",
    "    explained_var = explained_variance_score(y_true, y_pred)\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'MAPE': mape,\n",
    "        'Explained_Variance': explained_var,\n",
    "        'Residual_Std': residual_std,\n",
    "        'Mean_Residual': mean_residual\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate our neural network\n",
    "nn_metrics = evaluate_regression_model(y_test, test_pred_original, \"Neural Network\")\n",
    "\n",
    "print(\"DETAILED REGRESSION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: Neural Network Regressor\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Display metrics in organized format\n",
    "print(\"üìä CORE REGRESSION METRICS:\")\n",
    "print(f\"  Mean Squared Error (MSE):      {nn_metrics['MSE']:.6f}\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): {nn_metrics['RMSE']:.4f}\")\n",
    "print(f\"  Mean Absolute Error (MAE):     {nn_metrics['MAE']:.4f}\")\n",
    "print(f\"  R¬≤ Score:                      {nn_metrics['R¬≤']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"üìà ADDITIONAL METRICS:\")\n",
    "print(f\"  Mean Absolute Percentage Error: {nn_metrics['MAPE']:.2f}%\")\n",
    "print(f\"  Explained Variance Score:      {nn_metrics['Explained_Variance']:.4f}\")\n",
    "print(f\"  Residual Standard Deviation:   {nn_metrics['Residual_Std']:.4f}\")\n",
    "print(f\"  Mean Residual (Bias):          {nn_metrics['Mean_Residual']:.4f}\")\n",
    "print()\n",
    "\n",
    "# Quality control specific metrics\n",
    "quality_ranges = [(3.0, 4.0), (4.0, 5.0), (5.0, 6.0), (6.0, 7.0), (7.0, 8.0), (8.0, 9.0)]\n",
    "print(\"üéØ QUALITY RANGE SPECIFIC PERFORMANCE:\")\n",
    "for low, high in quality_ranges:\n",
    "    mask = (y_test >= low) & (y_test < high)\n",
    "    if mask.sum() > 0:\n",
    "        range_mae = mean_absolute_error(y_test[mask], test_pred_original[mask])\n",
    "        range_r2 = r2_score(y_test[mask], test_pred_original[mask])\n",
    "        print(f\"  Quality {low:.0f}-{high:.0f} (n={mask.sum():2d}): MAE={range_mae:.3f}, R¬≤={range_r2:.3f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Create detailed metrics visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 5))\n",
    "\n",
    "# 1. Metrics comparison (bar chart)\n",
    "metrics_names = ['RMSE', 'MAE', 'R¬≤', 'Explained\\nVariance']\n",
    "metrics_values = [nn_metrics['RMSE'], nn_metrics['MAE'], nn_metrics['R¬≤'], nn_metrics['Explained_Variance']]\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen', 'lightyellow']\n",
    "\n",
    "bars = axes[0,0].bar(metrics_names, metrics_values, color=colors, edgecolor='black')\n",
    "axes[0,0].set_title('Neural Network Regression Metrics')\n",
    "axes[0,0].set_ylabel('Metric Value')\n",
    "axes[0,0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Error distribution by quality level\n",
    "quality_bins = np.arange(3, 10, 1)\n",
    "quality_digitized = np.digitize(y_test, quality_bins)\n",
    "error_by_quality = [np.abs(y_test[quality_digitized == i] - test_pred_original[quality_digitized == i]) \n",
    "                   for i in range(1, len(quality_bins))]\n",
    "\n",
    "axes[0,1].boxplot(error_by_quality, labels=[f'{q:.0f}-{q+1:.0f}' for q in quality_bins[:-1]])\n",
    "axes[0,1].set_xlabel('Quality Range')\n",
    "axes[0,1].set_ylabel('Absolute Error')\n",
    "axes[0,1].set_title('Prediction Error by Quality Level')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Prediction confidence intervals\n",
    "sorted_indices = np.argsort(y_test)\n",
    "y_test_sorted = y_test.iloc[sorted_indices]\n",
    "y_pred_sorted = test_pred_original[sorted_indices]\n",
    "\n",
    "# Calculate confidence intervals (using residual std as approximation)\n",
    "ci_lower = y_pred_sorted - 1.96 * nn_metrics['Residual_Std']\n",
    "ci_upper = y_pred_sorted + 1.96 * nn_metrics['Residual_Std']\n",
    "\n",
    "sample_indices = np.linspace(0, len(y_test_sorted)-1, 50, dtype=int)\n",
    "\n",
    "axes[1,0].fill_between(range(len(sample_indices)), ci_lower[sample_indices], ci_upper[sample_indices], \n",
    "                       alpha=0.3, color='gray', label='95% Confidence Interval')\n",
    "axes[1,0].plot(range(len(sample_indices)), y_test_sorted.iloc[sample_indices], 'ro', markersize=4, label='Actual')\n",
    "axes[1,0].plot(range(len(sample_indices)), y_pred_sorted[sample_indices], 'bo', markersize=4, label='Predicted')\n",
    "axes[1,0].set_xlabel('Sample Index (sorted by actual quality)')\n",
    "axes[1,0].set_ylabel('Quality Score')\n",
    "axes[1,0].set_title('Predictions with Confidence Intervals')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Model performance summary\n",
    "performance_text = f\"\"\"\n",
    "REGRESSION PERFORMANCE SUMMARY\n",
    "\n",
    "Core Metrics:\n",
    "‚Ä¢ RMSE: {nn_metrics['RMSE']:.3f} quality points\n",
    "‚Ä¢ MAE:  {nn_metrics['MAE']:.3f} quality points  \n",
    "‚Ä¢ R¬≤:   {nn_metrics['R¬≤']:.3f} ({nn_metrics['R¬≤']*100:.1f}% variance explained)\n",
    "\n",
    "Quality Assessment:\n",
    "‚Ä¢ Mean prediction error: ¬±{nn_metrics['MAE']:.2f}\n",
    "‚Ä¢ 95% predictions within: ¬±{1.96*nn_metrics['Residual_Std']:.2f}\n",
    "‚Ä¢ Model bias: {nn_metrics['Mean_Residual']:.3f}\n",
    "\n",
    "Industrial Suitability:\n",
    "\"\"\"\n",
    "\n",
    "if nn_metrics['MAE'] <= 0.3:\n",
    "    performance_text += \"‚úÖ EXCELLENT - High precision for quality control\"\n",
    "elif nn_metrics['MAE'] <= 0.5:\n",
    "    performance_text += \"‚úÖ GOOD - Suitable for industrial applications\"\n",
    "else:\n",
    "    performance_text += \"‚ö†Ô∏è NEEDS IMPROVEMENT - Consider model tuning\"\n",
    "\n",
    "axes[1,1].text(0.05, 0.95, performance_text, transform=axes[1,1].transAxes, fontsize=10,\n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "axes[1,1].set_title('Performance Summary')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison with perfect prediction baseline\n",
    "print(\"\\nüéØ BASELINE COMPARISONS:\")\n",
    "print(f\"  Predicting mean quality (baseline): MAE = {mean_absolute_error(y_test, [y_train.mean()]*len(y_test)):.3f}\")\n",
    "print(f\"  Neural Network Model:               MAE = {nn_metrics['MAE']:.3f}\")\n",
    "print(f\"  Improvement over baseline:          {(1 - nn_metrics['MAE']/mean_absolute_error(y_test, [y_train.mean()]*len(y_test)))*100:.1f}%\")\n",
    "\n",
    "# Statistical significance of predictions\n",
    "from scipy.stats import pearsonr\n",
    "pearson_corr, pearson_p = pearsonr(y_test, test_pred_original)\n",
    "print(f\"\\nüìä STATISTICAL SIGNIFICANCE:\")\n",
    "print(f\"  Pearson correlation: {pearson_corr:.4f} (p-value: {pearson_p:.2e})\")\n",
    "print(f\"  Prediction-actual correlation is {'significant' if pearson_p < 0.05 else 'not significant'} at Œ±=0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b83575",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis for Regression\n",
    "\n",
    "Calculate and visualize feature importance for regression models using gradient-based methods and compare with linear regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824802d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis for regression models\n",
    "\n",
    "def calculate_regression_feature_importance(model, X_data, method='gradient'):\n",
    "    \"\"\"Calculate feature importance for regression neural network\"\"\"\n",
    "    model.eval()\n",
    "    feature_importances = []\n",
    "    \n",
    "    for i in range(len(X_data)):\n",
    "        x_sample = X_data[i:i+1].clone().detach().requires_grad_(True)\n",
    "        output = model(x_sample)\n",
    "        \n",
    "        # Use output value directly for regression\n",
    "        output.backward()\n",
    "        \n",
    "        # Get gradient magnitude\n",
    "        importance = x_sample.grad.abs().cpu().numpy().flatten()\n",
    "        feature_importances.append(importance)\n",
    "    \n",
    "    # Average importance across all samples\n",
    "    avg_importance = np.mean(feature_importances, axis=0)\n",
    "    return avg_importance\n",
    "\n",
    "# Calculate neural network feature importance\n",
    "print(\"Calculating Feature Importance...\")\n",
    "nn_importance = calculate_regression_feature_importance(wine_regressor, X_test_tensor)\n",
    "\n",
    "# Compare with linear regression coefficients\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "linear_importance = np.abs(linear_reg.coef_)\n",
    "\n",
    "# Random Forest for comparison\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train_scaled, y_train)\n",
    "rf_importance = rf_reg.feature_importances_\n",
    "\n",
    "# Ridge regression for comparison (handles multicollinearity)\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "ridge_importance = np.abs(ridge_reg.coef_)\n",
    "\n",
    "# Organize feature importance data\n",
    "feature_names = X.columns.tolist()\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Neural_Network': nn_importance,\n",
    "    'Linear_Regression': linear_importance,\n",
    "    'Random_Forest': rf_importance,\n",
    "    'Ridge_Regression': ridge_importance\n",
    "})\n",
    "\n",
    "# Normalize importances for comparison (0-1 scale)\n",
    "importance_cols = ['Neural_Network', 'Linear_Regression', 'Random_Forest', 'Ridge_Regression']\n",
    "for col in importance_cols:\n",
    "    importance_df[f'{col}_norm'] = importance_df[col] / importance_df[col].max()\n",
    "\n",
    "# Sort by neural network importance\n",
    "importance_df = importance_df.sort_values('Neural_Network', ascending=True)\n",
    "\n",
    "print(\"\\nFEATURE IMPORTANCE ANALYSIS (REGRESSION)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create comprehensive feature importance visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# 1. Neural Network vs Linear Regression\n",
    "axes[0,0].barh(importance_df['Feature'], importance_df['Neural_Network_norm'], \n",
    "               color='lightblue', alpha=0.7, label='Neural Network')\n",
    "axes[0,0].barh(importance_df['Feature'], importance_df['Linear_Regression_norm'], \n",
    "               color='lightcoral', alpha=0.5, label='Linear Regression')\n",
    "axes[0,0].set_xlabel('Normalized Importance')\n",
    "axes[0,0].set_title('Neural Network vs Linear Regression')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. All models comparison\n",
    "width = 0.2\n",
    "x_pos = np.arange(len(feature_names))\n",
    "\n",
    "axes[0,1].barh(x_pos - 1.5*width, importance_df['Neural_Network_norm'], width, \n",
    "               label='Neural Network', alpha=0.8, color='blue')\n",
    "axes[0,1].barh(x_pos - 0.5*width, importance_df['Linear_Regression_norm'], width, \n",
    "               label='Linear Reg', alpha=0.8, color='red')\n",
    "axes[0,1].barh(x_pos + 0.5*width, importance_df['Random_Forest_norm'], width, \n",
    "               label='Random Forest', alpha=0.8, color='green')\n",
    "axes[0,1].barh(x_pos + 1.5*width, importance_df['Ridge_Regression_norm'], width, \n",
    "               label='Ridge Reg', alpha=0.8, color='purple')\n",
    "\n",
    "axes[0,1].set_yticks(x_pos)\n",
    "axes[0,1].set_yticklabels(importance_df['Feature'])\n",
    "axes[0,1].set_xlabel('Normalized Importance')\n",
    "axes[0,1].set_title('All Models Feature Importance Comparison')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Feature correlation with target\n",
    "target_corr = df.corr()['quality'].drop('quality').abs().sort_values(ascending=True)\n",
    "axes[1,0].barh(target_corr.index, target_corr.values, color='gold', alpha=0.7)\n",
    "axes[1,0].set_xlabel('Absolute Correlation with Quality')\n",
    "axes[1,0].set_title('Feature-Target Correlation (Ground Truth)')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Importance ranking comparison - Fix the TypeError here\n",
    "# Ensure we only use features that exist in both importance_df and target_corr\n",
    "common_features = [f for f in feature_names if f in target_corr.index]\n",
    "\n",
    "# Create rankings only for common features\n",
    "rankings = pd.DataFrame({\n",
    "    'Feature': common_features,\n",
    "    'NN_rank': importance_df[importance_df['Feature'].isin(common_features)]['Neural_Network'].rank(ascending=False).values,\n",
    "    'Linear_rank': importance_df[importance_df['Feature'].isin(common_features)]['Linear_Regression'].rank(ascending=False).values,\n",
    "    'RF_rank': importance_df[importance_df['Feature'].isin(common_features)]['Random_Forest'].rank(ascending=False).values,\n",
    "    'Corr_rank': target_corr.loc[common_features].rank(ascending=False).values\n",
    "})\n",
    "\n",
    "# Plot ranking comparison\n",
    "for i, feature in enumerate(common_features):\n",
    "    feature_data = rankings[rankings['Feature'] == feature]\n",
    "    axes[1,1].plot([1, 2, 3, 4], [feature_data['NN_rank'].values[0], \n",
    "                                  feature_data['Linear_rank'].values[0],\n",
    "                                  feature_data['RF_rank'].values[0],\n",
    "                                  feature_data['Corr_rank'].values[0]], \n",
    "                   'o-', alpha=0.7, linewidth=2, markersize=6, label=feature)\n",
    "\n",
    "axes[1,1].set_xticks([1, 2, 3, 4])\n",
    "axes[1,1].set_xticklabels(['Neural\\nNetwork', 'Linear\\nReg', 'Random\\nForest', 'Correlation'])\n",
    "axes[1,1].set_ylabel('Feature Rank (1 = Most Important)')\n",
    "axes[1,1].set_title('Feature Importance Rankings Across Methods')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].invert_yaxis()\n",
    "axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed importance rankings\n",
    "print(\"FEATURE IMPORTANCE RANKINGS (Regression Models)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "methods = ['Neural_Network', 'Linear_Regression', 'Random_Forest', 'Ridge_Regression']\n",
    "method_names = ['Neural Network', 'Linear Regression', 'Random Forest', 'Ridge Regression']\n",
    "\n",
    "for method, name in zip(methods, method_names):\n",
    "    print(f\"\\n{name} Feature Importance:\")\n",
    "    sorted_features = importance_df.sort_values(method, ascending=False)\n",
    "    for i, (_, row) in enumerate(sorted_features.iterrows(), 1):\n",
    "        print(f\"  {i:2d}. {row['Feature']:<25}: {row[method]:.4f}\")\n",
    "\n",
    "# Feature importance consensus\n",
    "print(f\"\\nüéØ FEATURE IMPORTANCE CONSENSUS:\")\n",
    "print(f\"Features consistently ranked high across models:\")\n",
    "\n",
    "# Calculate average rank across methods\n",
    "avg_ranks = rankings[['NN_rank', 'Linear_rank', 'RF_rank', 'Corr_rank']].mean(axis=1)\n",
    "consensus_ranking = rankings.copy()\n",
    "consensus_ranking['avg_rank'] = avg_ranks\n",
    "consensus_ranking = consensus_ranking.sort_values('avg_rank')\n",
    "\n",
    "print(\"\\nConsensus Ranking (Average across all methods):\")\n",
    "for i, (_, row) in enumerate(consensus_ranking.head(8).iterrows(), 1):\n",
    "    print(f\"  {i}. {row['Feature']:<25} (Avg Rank: {row['avg_rank']:.1f})\")\n",
    "\n",
    "# Industrial insights\n",
    "print(f\"\\nüè≠ INDUSTRIAL QUALITY CONTROL INSIGHTS:\")\n",
    "top_features = consensus_ranking.head(5)['Feature'].tolist()\n",
    "print(f\"  üîç Monitor these key parameters for quality control:\")\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    feature_clean = feature.replace('_', ' ').title()\n",
    "    print(f\"    {i}. {feature_clean}\")\n",
    "\n",
    "print(f\"\\n  üí° Process Control Recommendations:\")\n",
    "print(f\"    ‚Ä¢ Primary control: {top_features[0].replace('_', ' ').title()}\")\n",
    "print(f\"    ‚Ä¢ Secondary control: {top_features[1].replace('_', ' ').title()}\")\n",
    "print(f\"    ‚Ä¢ Monitor closely: {top_features[2].replace('_', ' ').title()}\")\n",
    "\n",
    "# Model agreement analysis\n",
    "print(f\"\\nüìä MODEL AGREEMENT ANALYSIS:\")\n",
    "rank_correlations = rankings[['NN_rank', 'Linear_rank', 'RF_rank', 'Corr_rank']].corr()\n",
    "print(f\"  Spearman correlation between ranking methods:\")\n",
    "for i, method1 in enumerate(['NN_rank', 'Linear_rank', 'RF_rank']):\n",
    "    for method2 in ['Linear_rank', 'RF_rank', 'Corr_rank'][i:]:\n",
    "        if method1 != method2:\n",
    "            corr = stats.spearmanr(rankings[method1], rankings[method2])[0]\n",
    "            name1 = method1.replace('_rank', '').replace('_', ' ').title()\n",
    "            name2 = method2.replace('_rank', '').replace('_', ' ').title()\n",
    "            print(f\"    {name1} ‚Üî {name2}: {corr:.3f}\")\n",
    "            \n",
    "agreement_score = np.mean([stats.spearmanr(rankings[m1], rankings[m2])[0] \n",
    "                          for i, m1 in enumerate(['NN_rank', 'Linear_rank', 'RF_rank']) \n",
    "                          for m2 in ['Linear_rank', 'RF_rank', 'Corr_rank'][i:] if m1 != m2])\n",
    "print(f\"  Overall agreement score: {agreement_score:.3f} {'(Strong)' if agreement_score > 0.7 else '(Moderate)' if agreement_score > 0.5 else '(Weak)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca815b8a",
   "metadata": {},
   "source": [
    "## 9. Interactive Multi-Model Regression Comparison\n",
    "\n",
    "Compare different regression algorithms including Neural Networks, Random Forest, Linear Regression, and Support Vector Regression with interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_regression_comparison(model_type='Neural Network', \n",
    "                                    hidden_sizes='128,64,32', \n",
    "                                    learning_rate=0.001, \n",
    "                                    epochs=300,\n",
    "                                    alpha=1.0):\n",
    "    \"\"\"Interactive regression model comparison\"\"\"\n",
    "    \n",
    "    print(f\"Training {model_type} for Wine Quality Regression...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if model_type == 'Neural Network':\n",
    "        # Parse hidden sizes\n",
    "        try:\n",
    "            hidden_list = [int(x.strip()) for x in hidden_sizes.split(',')]\n",
    "        except:\n",
    "            hidden_list = [128, 64, 32]\n",
    "        \n",
    "        # Create and train neural network\n",
    "        model = WineQualityRegressor(\n",
    "            input_size=X_train_tensor.shape[1],\n",
    "            hidden_sizes=hidden_list,\n",
    "            dropout_rate=0.2\n",
    "        ).to(device)\n",
    "        \n",
    "        # Train model\n",
    "        training_results = train_wine_regressor(\n",
    "            model, X_train_tensor, y_train_tensor, \n",
    "            X_test_tensor, y_test_tensor,\n",
    "            lr=learning_rate, epochs=epochs, print_every=epochs//4\n",
    "        )\n",
    "        \n",
    "        # Get predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_pred_scaled = model(X_test_tensor)\n",
    "        \n",
    "        test_pred = scaler_y.inverse_transform(test_pred_scaled.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Uncertainty estimation\n",
    "        test_mean_pred, test_std_pred = model.predict_with_uncertainty(X_test_tensor, num_samples=30)\n",
    "        test_uncertainty = test_std_pred * scaler_y.scale_[0]\n",
    "        \n",
    "        has_training_curves = True\n",
    "        \n",
    "    else:\n",
    "        # Sklearn models\n",
    "        if model_type == 'Linear Regression':\n",
    "            model = LinearRegression()\n",
    "        elif model_type == 'Ridge Regression':\n",
    "            model = Ridge(alpha=alpha)\n",
    "        elif model_type == 'Lasso Regression':\n",
    "            model = Lasso(alpha=alpha, max_iter=2000)\n",
    "        elif model_type == 'Random Forest':\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'Gradient Boosting':\n",
    "            model = GradientBoostingRegressor(random_state=42)\n",
    "        elif model_type == 'Support Vector Regression':\n",
    "            model = SVR(C=alpha, kernel='rbf')\n",
    "        elif model_type == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "            model = xgb.XGBRegressor(random_state=42)\n",
    "        else:\n",
    "            print(f\"Model {model_type} not available\")\n",
    "            return\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        test_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Estimate uncertainty using residual analysis\n",
    "        train_pred = model.predict(X_train_scaled)\n",
    "        residual_std = np.std(y_train - train_pred)\n",
    "        test_uncertainty = np.full(len(test_pred), residual_std)\n",
    "        \n",
    "        training_results = None\n",
    "        has_training_curves = False\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = evaluate_regression_model(y_test, test_pred, model_type)\n",
    "    \n",
    "    # Create visualizations\n",
    "    if has_training_curves:\n",
    "        fig = plt.figure(figsize=(9, 6))\n",
    "        # 2x3 layout for neural network\n",
    "        ax1 = plt.subplot(2, 3, 1)\n",
    "        ax2 = plt.subplot(2, 3, 2)\n",
    "        ax3 = plt.subplot(2, 3, 3)\n",
    "        ax4 = plt.subplot(2, 3, 4)\n",
    "        ax5 = plt.subplot(2, 3, 5)\n",
    "        ax6 = plt.subplot(2, 3, 6)\n",
    "        \n",
    "        # Training curves\n",
    "        ax1.plot(training_results['train_losses'], label='Train Loss', color='blue', linewidth=2)\n",
    "        ax1.plot(training_results['test_losses'], label='Test Loss', color='red', linewidth=2)\n",
    "        ax1.set_title(f'{model_type} - Training Loss (MSE)')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('MSE Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot(training_results['train_r2s'], label='Train R¬≤', color='blue', linewidth=2)\n",
    "        ax2.plot(training_results['test_r2s'], label='Test R¬≤', color='red', linewidth=2)\n",
    "        ax2.set_title(f'{model_type} - R¬≤ Score')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('R¬≤ Score')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "    else:\n",
    "        fig = plt.figure(figsize=(18, 8))\n",
    "        # 2x3 layout for sklearn models\n",
    "        ax3 = plt.subplot(2, 3, 1)\n",
    "        ax4 = plt.subplot(2, 3, 2)\n",
    "        ax5 = plt.subplot(2, 3, 3)\n",
    "        ax6 = plt.subplot(2, 3, 4)\n",
    "        \n",
    "        # Model performance summary\n",
    "        perf_text = f\"\"\"{model_type} Performance:\n",
    "        \n",
    "RMSE: {metrics['RMSE']:.3f}\n",
    "MAE:  {metrics['MAE']:.3f}\n",
    "R¬≤:   {metrics['R¬≤']:.3f}\n",
    "MAPE: {metrics['MAPE']:.1f}%\n",
    "\n",
    "Quality Assessment:\n",
    "{'‚úÖ Excellent' if metrics['MAE'] <= 0.3 else '‚úÖ Good' if metrics['MAE'] <= 0.5 else '‚ö†Ô∏è Needs Improvement'}\n",
    "        \"\"\"\n",
    "        \n",
    "        ax3.text(0.05, 0.95, perf_text, transform=ax3.transAxes, fontsize=12,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        ax3.set_title(f'{model_type} - Performance Summary')\n",
    "        ax3.axis('off')\n",
    "    \n",
    "    # Prediction vs Actual\n",
    "    min_qual = min(y_test.min(), test_pred.min()) - 0.2\n",
    "    max_qual = max(y_test.max(), test_pred.max()) + 0.2\n",
    "    \n",
    "    ax4.scatter(y_test, test_pred, alpha=0.6, color='blue', s=40)\n",
    "    ax4.plot([min_qual, max_qual], [min_qual, max_qual], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Add confidence bands if available\n",
    "    if model_type == 'Neural Network':\n",
    "        # Show uncertainty as error bars for a subset of points\n",
    "        sample_indices = np.random.choice(len(y_test), min(50, len(y_test)), replace=False)\n",
    "        ax4.errorbar(y_test.iloc[sample_indices], test_pred[sample_indices], \n",
    "                    yerr=test_uncertainty[sample_indices], fmt='none', alpha=0.3, color='gray')\n",
    "    \n",
    "    ax4.set_xlabel('Actual Quality')\n",
    "    ax4.set_ylabel('Predicted Quality')\n",
    "    ax4.set_title(f'{model_type} - Prediction vs Actual')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(min_qual, max_qual)\n",
    "    ax4.set_ylim(min_qual, max_qual)\n",
    "    \n",
    "    # Add R¬≤ annotation\n",
    "    ax4.text(0.05, 0.95, f'R¬≤ = {metrics[\"R¬≤\"]:.3f}', transform=ax4.transAxes, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Residual plot\n",
    "    residuals = y_test - test_pred\n",
    "    ax5.scatter(test_pred, residuals, alpha=0.6, color='green', s=40)\n",
    "    ax5.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    ax5.set_xlabel('Predicted Quality')\n",
    "    ax5.set_ylabel('Residuals')\n",
    "    ax5.set_title(f'{model_type} - Residual Analysis')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature importance (if available)\n",
    "    try:\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importance = np.abs(model.coef_)\n",
    "        elif model_type == 'Neural Network':\n",
    "            importance = calculate_regression_feature_importance(model, X_test_tensor)\n",
    "        else:\n",
    "            importance = np.ones(len(X.columns)) / len(X.columns)\n",
    "        \n",
    "        # Plot top features\n",
    "        top_n = min(8, len(X.columns))\n",
    "        top_indices = np.argsort(importance)[-top_n:]\n",
    "        top_features = [X.columns[i] for i in top_indices]\n",
    "        top_importance = importance[top_indices]\n",
    "        \n",
    "        ax6.barh(range(top_n), top_importance, color='lightcoral', alpha=0.7)\n",
    "        ax6.set_yticks(range(top_n))\n",
    "        ax6.set_yticklabels([f.replace('_', ' ').title() for f in top_features])\n",
    "        ax6.set_xlabel('Importance')\n",
    "        ax6.set_title(f'{model_type} - Feature Importance')\n",
    "        ax6.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "    except Exception as e:\n",
    "        ax6.text(0.5, 0.5, f'Feature importance\\nnot available\\nfor {model_type}', \n",
    "                transform=ax6.transAxes, ha='center', va='center')\n",
    "        ax6.set_title(f'{model_type} - Feature Importance')\n",
    "        ax6.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\n{model_type.upper()} REGRESSION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"RMSE:              {metrics['RMSE']:.4f} quality points\")\n",
    "    print(f\"MAE:               {metrics['MAE']:.4f} quality points\")\n",
    "    print(f\"R¬≤ Score:          {metrics['R¬≤']:.4f} ({metrics['R¬≤']*100:.1f}% variance explained)\")\n",
    "    print(f\"MAPE:              {metrics['MAPE']:.2f}%\")\n",
    "    print(f\"Residual Std:      {metrics['Residual_Std']:.4f}\")\n",
    "    \n",
    "    # Quality control assessment\n",
    "    precision_level = \"EXCELLENT\" if metrics['MAE'] <= 0.3 else \"GOOD\" if metrics['MAE'] <= 0.5 else \"NEEDS IMPROVEMENT\"\n",
    "    print(f\"\\nQuality Control Assessment: {precision_level}\")\n",
    "    \n",
    "    # Uncertainty analysis\n",
    "    avg_uncertainty = np.mean(test_uncertainty)\n",
    "    print(f\"Average Prediction Uncertainty: ¬±{avg_uncertainty:.3f} quality points\")\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "# Create model options for regression\n",
    "regression_models = ['Neural Network', 'Linear Regression', 'Ridge Regression', \n",
    "                    'Lasso Regression', 'Random Forest', 'Gradient Boosting', \n",
    "                    'Support Vector Regression']\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    regression_models.append('XGBoost')\n",
    "\n",
    "# Create interactive widget\n",
    "print(\"INTERACTIVE REGRESSION MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Compare different regression models for wine quality prediction:\")\n",
    "\n",
    "interact(interactive_regression_comparison,\n",
    "         model_type=widgets.Dropdown(options=regression_models, value='Neural Network', \n",
    "                                    description='Model:'),\n",
    "         hidden_sizes=widgets.Text(value='128,64,32,16', description='Hidden Layers:', \n",
    "                                  placeholder='e.g., 128,64,32'),\n",
    "         learning_rate=widgets.FloatSlider(value=0.001, min=0.0001, max=0.01, step=0.0001, \n",
    "                                         description='Learning Rate:'),\n",
    "         epochs=widgets.IntSlider(value=300, min=100, max=600, step=50, \n",
    "                                description='Epochs:'),\n",
    "         alpha=widgets.FloatSlider(value=1.0, min=0.01, max=10.0, step=0.1, \n",
    "                                 description='Alpha (Reg):'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602fe649",
   "metadata": {},
   "source": [
    "## 10. Industrial Quality Control with Continuous Scores\n",
    "\n",
    "Implement a quality control dashboard that provides continuous quality scores with confidence intervals and uncertainty estimates for industrial applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af734773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_control_dashboard_regression(wine_params):\n",
    "    \"\"\"Advanced quality control dashboard with continuous scoring and uncertainty estimation\"\"\"\n",
    "    \n",
    "    # Parse input parameters\n",
    "    try:\n",
    "        params = [float(x.strip()) for x in wine_params.split(',')]\n",
    "        if len(params) != 11:\n",
    "            print(\"Error: Please provide exactly 11 parameters\")\n",
    "            return\n",
    "    except:\n",
    "        print(\"Error: Please provide valid numeric parameters\")\n",
    "        return\n",
    "    \n",
    "    # Feature names for reference\n",
    "    param_names = [\n",
    "        'Fixed Acidity', 'Volatile Acidity', 'Citric Acid', 'Residual Sugar',\n",
    "        'Chlorides', 'Free SO2', 'Total SO2', 'Density', 'pH', 'Sulphates', 'Alcohol'\n",
    "    ]\n",
    "    \n",
    "    # Create input array and scale it\n",
    "    input_array = np.array([params]).reshape(1, -1)\n",
    "    input_scaled = scaler_X.transform(input_array)\n",
    "    input_tensor = torch.FloatTensor(input_scaled).to(device)\n",
    "    \n",
    "    # Make prediction with uncertainty estimation\n",
    "    wine_regressor.eval()\n",
    "    \n",
    "    # Point prediction\n",
    "    with torch.no_grad():\n",
    "        output_scaled = wine_regressor(input_tensor)\n",
    "    \n",
    "    predicted_quality = scaler_y.inverse_transform(output_scaled.cpu().numpy().reshape(-1, 1))[0, 0]\n",
    "    \n",
    "    # Uncertainty estimation using Monte Carlo Dropout - Fixed version\n",
    "    # We need to enable only dropout while keeping batch norm in eval mode\n",
    "    def enable_dropout_only(model):\n",
    "        \"\"\"Enable only dropout layers while keeping batch norm in eval mode\"\"\"\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                module.train()\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                module.eval()  # Keep batch norm in eval mode\n",
    "    \n",
    "    # Alternative uncertainty estimation using multiple forward passes with dropout\n",
    "    wine_regressor.eval()  # Set base model to eval\n",
    "    enable_dropout_only(wine_regressor)  # Enable only dropout\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(100):\n",
    "            pred = wine_regressor(input_tensor)\n",
    "            predictions.append(pred.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    mean_pred_scaled = np.mean(predictions, axis=0)\n",
    "    std_pred_scaled = np.std(predictions, axis=0)\n",
    "    \n",
    "    mean_pred = scaler_y.inverse_transform(mean_pred_scaled.reshape(-1, 1))[0, 0]\n",
    "    # Handle scalar case for std_pred_scaled\n",
    "    if np.isscalar(std_pred_scaled):\n",
    "        std_pred = std_pred_scaled * scaler_y.scale_[0]\n",
    "    else:\n",
    "        std_pred = std_pred_scaled[0] * scaler_y.scale_[0]  # Scale the standard deviation\n",
    "    \n",
    "    # Reset model to eval mode\n",
    "    wine_regressor.eval()\n",
    "    \n",
    "    # Confidence intervals (95%)\n",
    "    ci_lower = mean_pred - 1.96 * std_pred\n",
    "    ci_upper = mean_pred + 1.96 * std_pred\n",
    "    \n",
    "    # Quality assessment with continuous scale\n",
    "    if predicted_quality >= 8.0:\n",
    "        quality_status = \"EXCEPTIONAL\"\n",
    "        status_color = \"üü¢\"\n",
    "        grade = \"A+\"\n",
    "        recommendation = \"Premium product - highest market tier\"\n",
    "    elif predicted_quality >= 7.0:\n",
    "        quality_status = \"EXCELLENT\"\n",
    "        status_color = \"üü¢\" \n",
    "        grade = \"A\"\n",
    "        recommendation = \"High-quality product - premium market\"\n",
    "    elif predicted_quality >= 6.5:\n",
    "        quality_status = \"VERY GOOD\"\n",
    "        status_color = \"üü°\"\n",
    "        grade = \"B+\"\n",
    "        recommendation = \"Above-average quality - standard premium\"\n",
    "    elif predicted_quality >= 6.0:\n",
    "        quality_status = \"GOOD\"\n",
    "        status_color = \"üü°\"\n",
    "        grade = \"B\"\n",
    "        recommendation = \"Standard quality - regular market\"\n",
    "    elif predicted_quality >= 5.5:\n",
    "        quality_status = \"ACCEPTABLE\"\n",
    "        status_color = \"üü†\"\n",
    "        grade = \"C+\"\n",
    "        recommendation = \"Below-average - consider process adjustment\"\n",
    "    elif predicted_quality >= 5.0:\n",
    "        quality_status = \"POOR\"\n",
    "        status_color = \"üü†\"\n",
    "        grade = \"C\"\n",
    "        recommendation = \"Low quality - blending or price reduction\"\n",
    "    else:\n",
    "        quality_status = \"UNACCEPTABLE\"\n",
    "        status_color = \"üî¥\"\n",
    "        grade = \"D\"\n",
    "        recommendation = \"Reject - investigate process issues\"\n",
    "    \n",
    "    # Uncertainty assessment\n",
    "    if std_pred <= 0.2:\n",
    "        uncertainty_level = \"LOW (High Confidence)\"\n",
    "        uncertainty_color = \"üü¢\"\n",
    "    elif std_pred <= 0.4:\n",
    "        uncertainty_level = \"MODERATE\"\n",
    "        uncertainty_color = \"üü°\"\n",
    "    else:\n",
    "        uncertainty_level = \"HIGH (Low Confidence)\"\n",
    "        uncertainty_color = \"üî¥\"\n",
    "    \n",
    "    # Display results\n",
    "    print(\"ADVANCED WINE QUALITY CONTROL DASHBOARD (REGRESSION)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"üìä INPUT PARAMETERS:\")\n",
    "    for name, value in zip(param_names, params):\n",
    "        print(f\"  {name:<20}: {value:>8.3f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üéØ QUALITY PREDICTION (CONTINUOUS SCORING):\")\n",
    "    print(f\"  Predicted Quality Score:    {predicted_quality:.3f} ¬± {std_pred:.3f}\")\n",
    "    print(f\"  Quality Grade:              {grade}\")\n",
    "    print(f\"  Status:                     {status_color} {quality_status}\")\n",
    "    print(f\"  95% Confidence Interval:    [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "    print(f\"  Prediction Uncertainty:     {uncertainty_color} {uncertainty_level}\")\n",
    "    print(f\"  Recommendation:             {recommendation}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üìà STATISTICAL CONFIDENCE:\")\n",
    "    confidence_score = max(0, min(100, (1 - std_pred / 2) * 100))  # Normalize to 0-100%\n",
    "    print(f\"  Confidence Score:           {confidence_score:.1f}%\")\n",
    "    print(f\"  Prediction Precision:       ¬±{std_pred:.3f} quality points\")\n",
    "    print(f\"  Model Reliability:          {'High' if std_pred <= 0.3 else 'Medium' if std_pred <= 0.5 else 'Low'}\")\n",
    "    print()\n",
    "    \n",
    "    # Parameter analysis with statistical context\n",
    "    print(\"üîç PARAMETER ANALYSIS:\")\n",
    "    \n",
    "    # Compare with training data statistics\n",
    "    train_stats = pd.DataFrame(X_train, columns=X.columns).describe()\n",
    "    \n",
    "    issues = []\n",
    "    insights = []\n",
    "    \n",
    "    for i, (name, value) in enumerate(zip(param_names, params)):\n",
    "        feature_name = X.columns[i]\n",
    "        mean_val = train_stats.loc['mean', feature_name]\n",
    "        std_val = train_stats.loc['std', feature_name]\n",
    "        z_score = (value - mean_val) / std_val\n",
    "        \n",
    "        if abs(z_score) > 2:\n",
    "            issues.append(f\"  ‚ö†Ô∏è  {name}: {value:.3f} (z-score: {z_score:.2f}, unusual)\")\n",
    "        elif abs(z_score) > 1:\n",
    "            insights.append(f\"  üí° {name}: {value:.3f} (z-score: {z_score:.2f}, notable)\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"  ANOMALIES DETECTED:\")\n",
    "        for issue in issues:\n",
    "            print(issue)\n",
    "    else:\n",
    "        print(\"  ‚úÖ All parameters within normal ranges\")\n",
    "    \n",
    "    if insights:\n",
    "        print(\"  NOTABLE OBSERVATIONS:\")\n",
    "        for insight in insights[:3]:  # Limit to top 3\n",
    "            print(insight)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Process control recommendations\n",
    "    print(\"üè≠ PROCESS CONTROL RECOMMENDATIONS:\")\n",
    "    \n",
    "    if predicted_quality >= 7.0 and std_pred <= 0.3:\n",
    "        print(\"  ‚úÖ OPTIMAL: Current process parameters are excellent\")\n",
    "        print(\"  üîß Action: Maintain current settings, monitor stability\")\n",
    "    elif predicted_quality >= 6.0 and std_pred <= 0.4:\n",
    "        print(\"  ‚úÖ ACCEPTABLE: Process within acceptable limits\")\n",
    "        print(\"  üîß Action: Minor optimization may improve quality\")\n",
    "    elif predicted_quality < 6.0 or std_pred > 0.4:\n",
    "        print(\"  ‚ö†Ô∏è  ATTENTION REQUIRED: Process adjustment needed\")\n",
    "        print(\"  üîß Action: Investigate parameter variations and optimize\")\n",
    "        \n",
    "        # Suggest top parameters to adjust based on feature importance\n",
    "        top_features = consensus_ranking.head(3)['Feature'].tolist()\n",
    "        print(\"  üìã Priority Parameters to Monitor:\")\n",
    "        for j, feature in enumerate(top_features, 1):\n",
    "            feature_clean = feature.replace('_', ' ').title()\n",
    "            print(f\"    {j}. {feature_clean}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Economic impact estimation\n",
    "    print(\"üí∞ ECONOMIC IMPACT ESTIMATION:\")\n",
    "    \n",
    "    # Simple economic model based on quality score\n",
    "    base_price = 15.0  # Base price per bottle\n",
    "    if predicted_quality >= 8.0:\n",
    "        price_multiplier = 2.0\n",
    "        market_segment = \"Premium/Luxury\"\n",
    "    elif predicted_quality >= 7.0:\n",
    "        price_multiplier = 1.5\n",
    "        market_segment = \"Premium\"\n",
    "    elif predicted_quality >= 6.0:\n",
    "        price_multiplier = 1.0\n",
    "        market_segment = \"Standard\"\n",
    "    elif predicted_quality >= 5.0:\n",
    "        price_multiplier = 0.7\n",
    "        market_segment = \"Economy\"\n",
    "    else:\n",
    "        price_multiplier = 0.4\n",
    "        market_segment = \"Discount/Blend\"\n",
    "    \n",
    "    estimated_price = base_price * price_multiplier\n",
    "    price_uncertainty = base_price * 0.1 * std_pred  # Price uncertainty\n",
    "    \n",
    "    print(f\"  Estimated Market Value:     ${estimated_price:.2f} ¬± ${price_uncertainty:.2f}\")\n",
    "    print(f\"  Market Segment:             {market_segment}\")\n",
    "    print(f\"  Quality Premium:            {(price_multiplier - 1) * 100:+.0f}%\")\n",
    "    \n",
    "    return {\n",
    "        'predicted_quality': predicted_quality,\n",
    "        'uncertainty': std_pred,\n",
    "        'confidence_interval': (ci_lower, ci_upper),\n",
    "        'grade': grade,\n",
    "        'status': quality_status,\n",
    "        'estimated_price': estimated_price\n",
    "    }\n",
    "\n",
    "# Example usage with different quality scenarios\n",
    "print(\"QUALITY CONTROL DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Scenario 1: High quality wine\n",
    "print(\"üç∑ SCENARIO 1: Premium Wine Sample\")\n",
    "print(\"-\" * 40)\n",
    "high_quality_params = \"7.2,0.35,0.45,2.1,0.065,22,95,0.9962,3.28,0.72,11.8\"\n",
    "result1 = quality_control_dashboard_regression(high_quality_params)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "\n",
    "# Scenario 2: Average quality wine\n",
    "print(\"üç∑ SCENARIO 2: Standard Wine Sample\")\n",
    "print(\"-\" * 40)\n",
    "avg_quality_params = \"8.1,0.55,0.15,2.8,0.085,35,145,0.9968,3.35,0.58,9.8\"\n",
    "result2 = quality_control_dashboard_regression(avg_quality_params)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "\n",
    "# Scenario 3: Poor quality wine\n",
    "print(\"üç∑ SCENARIO 3: Below-Standard Wine Sample\")\n",
    "print(\"-\" * 40)\n",
    "poor_quality_params = \"9.2,0.88,0.02,4.5,0.125,45,180,0.9975,3.55,0.42,8.5\"\n",
    "result3 = quality_control_dashboard_regression(poor_quality_params)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "\n",
    "# Interactive quality control interface\n",
    "def interactive_quality_control_regression(fixed_acidity=7.4, volatile_acidity=0.35, citric_acid=0.25,\n",
    "                                         residual_sugar=2.1, chlorides=0.065, free_sulfur_dioxide=25,\n",
    "                                         total_sulfur_dioxide=110, density=0.9965, pH=3.28,\n",
    "                                         sulphates=0.65, alcohol=10.5):\n",
    "    \n",
    "    params_string = f\"{fixed_acidity},{volatile_acidity},{citric_acid},{residual_sugar},{chlorides},{free_sulfur_dioxide},{total_sulfur_dioxide},{density},{pH},{sulphates},{alcohol}\"\n",
    "    return quality_control_dashboard_regression(params_string)\n",
    "\n",
    "print(\"\\\\nüéÆ INTERACTIVE QUALITY CONTROL SYSTEM\")\n",
    "print(\"Adjust the parameters below to test different wine compositions:\")\n",
    "print(\"Real-time regression-based quality prediction with uncertainty quantification\")\n",
    "\n",
    "interact(interactive_quality_control_regression,\n",
    "         fixed_acidity=widgets.FloatSlider(value=7.4, min=4.0, max=12.0, step=0.1, \n",
    "                                         description='Fixed Acidity:'),\n",
    "         volatile_acidity=widgets.FloatSlider(value=0.35, min=0.1, max=1.2, step=0.01, \n",
    "                                            description='Volatile Acidity:'),\n",
    "         citric_acid=widgets.FloatSlider(value=0.25, min=0.0, max=0.8, step=0.01, \n",
    "                                       description='Citric Acid:'),\n",
    "         residual_sugar=widgets.FloatSlider(value=2.1, min=0.5, max=15.0, step=0.1, \n",
    "                                          description='Residual Sugar:'),\n",
    "         chlorides=widgets.FloatSlider(value=0.065, min=0.01, max=0.2, step=0.001, \n",
    "                                     description='Chlorides:'),\n",
    "         free_sulfur_dioxide=widgets.IntSlider(value=25, min=1, max=80, step=1, \n",
    "                                             description='Free SO2:'),\n",
    "         total_sulfur_dioxide=widgets.IntSlider(value=110, min=10, max=300, step=5, \n",
    "                                              description='Total SO2:'),\n",
    "         density=widgets.FloatSlider(value=0.9965, min=0.990, max=1.005, step=0.0001, \n",
    "                                   description='Density:'),\n",
    "         pH=widgets.FloatSlider(value=3.28, min=2.5, max=4.0, step=0.01, \n",
    "                              description='pH:'),\n",
    "         sulphates=widgets.FloatSlider(value=0.65, min=0.3, max=1.5, step=0.01, \n",
    "                                     description='Sulphates:'),\n",
    "         alcohol=widgets.FloatSlider(value=10.5, min=8.0, max=15.0, step=0.1, \n",
    "                                   description='Alcohol %:'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8605e1",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways and Industrial Applications\n",
    "\n",
    "### **Regression vs Classification for Quality Control:**\n",
    "\n",
    "#### **üîç Regression Advantages:**\n",
    "- **Precise Measurements**: Get exact quality scores (6.23 vs just \"6\")\n",
    "- **Uncertainty Quantification**: Know prediction confidence (¬±0.3 quality points)\n",
    "- **Continuous Monitoring**: Track gradual quality changes over time\n",
    "- **Economic Optimization**: Link exact quality scores to pricing models\n",
    "- **Process Control**: Fine-tune parameters for optimal quality ranges\n",
    "\n",
    "#### **üìä Key Regression Metrics:**\n",
    "- **RMSE**: Root Mean Square Error - overall prediction accuracy\n",
    "- **MAE**: Mean Absolute Error - average prediction error in quality points  \n",
    "- **R¬≤**: Coefficient of Determination - % of variance explained by model\n",
    "- **Confidence Intervals**: Range of likely quality scores with statistical confidence\n",
    "\n",
    "### **Industrial Implementation:**\n",
    "\n",
    "#### **üè≠ Manufacturing Applications:**\n",
    "- **Pharmaceutical**: API purity scores with confidence intervals\n",
    "- **Food & Beverage**: Continuous quality scoring for process optimization\n",
    "- **Chemical Processing**: Precise composition quality prediction\n",
    "- **Automotive**: Component quality scores for assembly line decisions\n",
    "\n",
    "#### **‚ö° Real-time Process Control:**\n",
    "- **Predictive Quality Control**: Adjust parameters before quality drops\n",
    "- **Statistical Process Control**: Monitor quality trends with confidence bounds\n",
    "- **Economic Optimization**: Balance quality improvements vs production costs\n",
    "- **Automated Decision Making**: Set quality thresholds with uncertainty handling\n",
    "\n",
    "### **Model Performance Guidelines:**\n",
    "\n",
    "#### **üìà Regression Model Quality Assessment:**\n",
    "- **Excellent**: MAE ‚â§ 0.3, R¬≤ ‚â• 0.85 ‚Üí High-precision applications\n",
    "- **Good**: MAE ‚â§ 0.5, R¬≤ ‚â• 0.75 ‚Üí Standard industrial use\n",
    "- **Acceptable**: MAE ‚â§ 0.8, R¬≤ ‚â• 0.60 ‚Üí General monitoring\n",
    "- **Poor**: MAE > 0.8, R¬≤ < 0.60 ‚Üí Requires model improvement\n",
    "\n",
    "#### **üé≤ Uncertainty Management:**\n",
    "- **Low Uncertainty** (œÉ ‚â§ 0.2): High confidence predictions\n",
    "- **Medium Uncertainty** (0.2 < œÉ ‚â§ 0.4): Standard confidence\n",
    "- **High Uncertainty** (œÉ > 0.4): Low confidence - investigate\n",
    "\n",
    "### **Advanced Features Implemented:**\n",
    "\n",
    "#### **üß† Neural Network Regression:**\n",
    "- **Architecture**: Multi-layer networks with batch normalization\n",
    "- **Uncertainty Estimation**: Monte Carlo Dropout for prediction intervals\n",
    "- **Feature Importance**: Gradient-based importance analysis\n",
    "- **Regularization**: Dropout and weight decay for generalization\n",
    "\n",
    "#### **üìä Comprehensive Evaluation:**\n",
    "- **Residual Analysis**: Check for model bias and heteroscedasticity\n",
    "- **Prediction vs Actual**: Visual assessment of model performance  \n",
    "- **Cross-model Comparison**: Neural networks vs linear models vs ensemble methods\n",
    "- **Statistical Significance**: Correlation analysis and confidence testing\n",
    "\n",
    "### **Next Steps:**\n",
    "- **Deploy Model**: Integrate into real-time production monitoring systems\n",
    "- **Calibration**: Adjust uncertainty estimates using production data\n",
    "- **Ensemble Methods**: Combine multiple models for better predictions\n",
    "- **Online Learning**: Update model with new production data\n",
    "- **Multi-objective Optimization**: Balance quality, cost, and production speed\n",
    "\n",
    "---\n",
    "\n",
    "**This regression tutorial demonstrates how continuous quality prediction provides more nuanced and actionable insights compared to discrete classification, making it ideal for precision manufacturing and process optimization applications.**\n",
    "\n",
    "### **üöÄ Ready for Production:**\n",
    "Your regression model can now provide:\n",
    "- **Precise quality scores** with decimal precision\n",
    "- **Confidence intervals** for risk management\n",
    "- **Uncertainty quantification** for decision making\n",
    "- **Real-time process control** capabilities\n",
    "- **Economic impact assessment** for business decisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
