{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57b22b5",
   "metadata": {},
   "source": [
    "# üç∑ Wine Quality Classification Tutorial\n",
    "\n",
    "## **Industrial Quality Control with Machine Learning**\n",
    "\n",
    "### **Main Goal:**\n",
    "Learn to classify wine quality based on physicochemical properties, demonstrating how machine learning can be applied to industrial quality control processes. This tutorial uses real wine quality data to predict quality ratings from measurable parameters.\n",
    "\n",
    "### **Key Learning Objectives:**\n",
    "- **Multi-class Quality Assessment**: Classify products into quality grades (3-9 scale)\n",
    "- **Feature Engineering**: Handle imbalanced datasets and feature selection\n",
    "- **Model Comparison**: Compare different algorithms for quality control\n",
    "- **Industrial Applications**: Apply to manufacturing quality assessment\n",
    "- **Performance Optimization**: Handle real-world data challenges\n",
    "\n",
    "### **Industrial Relevance:**\n",
    "Apply to **product quality grading**, **process optimization**, **automated quality inspection**, and **production monitoring** in various industries.\n",
    "\n",
    "### **Interactive Features:**\n",
    "üéÆ Multi-model comparison | üìä Quality distribution analysis | ‚ö° Feature importance ranking | üî¨ Threshold optimization\n",
    "\n",
    "**Dataset**: Wine Quality Dataset with 11 physicochemical features and quality scores (0-10 scale)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3fee9",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll use comprehensive ML libraries for this advanced classification tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import fetch_openml\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "%matplotlib widget\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450df59",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Wine Quality Dataset\n",
    "\n",
    "Let's load the wine quality dataset and understand its structure for quality control applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic wine quality dataset (similar to UCI Wine Quality dataset)\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate synthetic wine quality data\n",
    "def generate_wine_data(n_samples):\n",
    "    # Create realistic wine chemistry features\n",
    "    fixed_acidity = np.random.normal(8.0, 1.5, n_samples)\n",
    "    volatile_acidity = np.random.normal(0.5, 0.2, n_samples)\n",
    "    citric_acid = np.random.normal(0.25, 0.15, n_samples)\n",
    "    residual_sugar = np.random.lognormal(1.5, 1.0, n_samples)\n",
    "    chlorides = np.random.normal(0.08, 0.03, n_samples)\n",
    "    free_sulfur_dioxide = np.random.normal(30, 15, n_samples)\n",
    "    total_sulfur_dioxide = np.random.normal(120, 40, n_samples)\n",
    "    density = np.random.normal(0.996, 0.002, n_samples)\n",
    "    pH = np.random.normal(3.2, 0.15, n_samples)\n",
    "    sulphates = np.random.normal(0.65, 0.15, n_samples)\n",
    "    alcohol = np.random.normal(10.5, 1.2, n_samples)\n",
    "    \n",
    "    # Create quality score based on feature combinations (realistic relationships)\n",
    "    quality_score = (\n",
    "        2.0 * (alcohol - 8) / 4 +  # Higher alcohol tends to increase quality\n",
    "        -5.0 * (volatile_acidity - 0.3) +  # Lower volatile acidity is better\n",
    "        2.0 * (citric_acid - 0.1) / 0.3 +  # More citric acid is good\n",
    "        -3.0 * np.abs(pH - 3.3) / 0.5 +  # pH around 3.3 is optimal\n",
    "        1.5 * (sulphates - 0.4) / 0.4 +  # More sulphates help\n",
    "        np.random.normal(0, 0.8, n_samples)  # Add noise\n",
    "    )\n",
    "    \n",
    "    # Convert to discrete quality ratings (3-9 scale, like real wine data)\n",
    "    quality = np.clip(np.round(quality_score + 6), 3, 9).astype(int)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'fixed_acidity': fixed_acidity,\n",
    "        'volatile_acidity': volatile_acidity,\n",
    "        'citric_acid': citric_acid,\n",
    "        'residual_sugar': residual_sugar,\n",
    "        'chlorides': chlorides,\n",
    "        'free_sulfur_dioxide': free_sulfur_dioxide,\n",
    "        'total_sulfur_dioxide': total_sulfur_dioxide,\n",
    "        'density': density,\n",
    "        'pH': pH,\n",
    "        'sulphates': sulphates,\n",
    "        'alcohol': alcohol,\n",
    "        'quality': quality\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate the dataset\n",
    "df = generate_wine_data(n_samples)\n",
    "\n",
    "print(\"Wine Quality Dataset Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {df.columns.tolist()[:-1]}\")\n",
    "print(f\"Target: {df.columns[-1]}\")\n",
    "print()\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nQuality Distribution:\")\n",
    "quality_counts = df['quality'].value_counts().sort_index()\n",
    "print(quality_counts)\n",
    "\n",
    "# Visualize quality distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "quality_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Wine Quality Distribution')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Number of Wines')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888d78d",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Feature Analysis\n",
    "\n",
    "Let's analyze the relationships between features and quality for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8062d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "plt.figure(figsize=(6, 5))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Features most correlated with quality\n",
    "quality_correlations = correlation_matrix['quality'].sort_values(ascending=False)\n",
    "print(\"Features most correlated with quality:\")\n",
    "print(\"=\" * 40)\n",
    "for feature, corr in quality_correlations.items():\n",
    "    if feature != 'quality':\n",
    "        print(f\"{feature:<20}: {corr:>6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis by quality\n",
    "features_to_plot = ['alcohol', 'volatile_acidity', 'citric_acid', 'pH']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    for quality in sorted(df['quality'].unique()):\n",
    "        subset = df[df['quality'] == quality][feature]\n",
    "        axes[i].hist(subset, alpha=0.6, label=f'Quality {quality}', bins=15)\n",
    "    \n",
    "    axes[i].set_xlabel(feature.replace('_', ' ').title())\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'Distribution of {feature.replace(\"_\", \" \").title()} by Quality')\n",
    "    axes[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70cc609",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Prepare the data for machine learning models with proper scaling and encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51402ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# For neural networks, we'll convert to class indices (0-based)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "unique_classes = sorted(df['quality'].unique())\n",
    "n_classes = len(unique_classes)\n",
    "\n",
    "print(\"Class encoding:\")\n",
    "for i, quality in enumerate(unique_classes):\n",
    "    print(f\"Quality {quality} -> Class {i}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors for neural network\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "print(f\"\\nData splits:\")\n",
    "print(f\"Training set: {X_train_tensor.shape}\")\n",
    "print(f\"Test set: {X_test_tensor.shape}\")\n",
    "print(f\"Number of features: {X_train_tensor.shape[1]}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# Class distribution in train/test sets\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Training: {train_dist.values}\")\n",
    "print(f\"Test:     {test_dist.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb7d77",
   "metadata": {},
   "source": [
    "## 5. Define Neural Network for Multi-class Classification\n",
    "\n",
    "Create a more sophisticated neural network for the wine quality classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64607a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineQualityClassifier(nn.Module):\n",
    "    def __init__(self, input_size=11, hidden_sizes=[64, 32], num_classes=7, dropout_rate=0.3):\n",
    "        super(WineQualityClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Hidden layers\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Create model\n",
    "wine_model = WineQualityClassifier(\n",
    "    input_size=X_train_tensor.shape[1],\n",
    "    hidden_sizes=[64, 32, 16],\n",
    "    num_classes=n_classes,\n",
    "    dropout_rate=0.3\n",
    ").to(device)\n",
    "\n",
    "print(wine_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in wine_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe513af5",
   "metadata": {},
   "source": [
    "## 6. Training Function for Multi-class Classification\n",
    "\n",
    "Enhanced training function with class weighting for imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wine_classifier(model, X_train, y_train, X_test, y_test, \n",
    "                         lr=0.001, epochs=300, print_every=50):\n",
    "    \n",
    "    # Calculate class weights for imbalanced data\n",
    "    class_counts = torch.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    class_weights = total_samples / (n_classes * class_counts.float())\n",
    "    class_weights = class_weights.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=20)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_outputs = model(X_train)\n",
    "        train_loss = criterion(train_outputs, y_train)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_accuracy = (train_predicted == y_train).float().mean()\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "            test_accuracy = (test_predicted == y_test).float().mean()\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        train_accuracies.append(train_accuracy.item())\n",
    "        test_accuracies.append(test_accuracy.item())\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            print(f'Train Loss: {train_loss.item():.4f}, Train Acc: {train_accuracy.item():.4f}')\n",
    "            print(f'Test Loss: {test_loss.item():.4f}, Test Acc: {test_accuracy.item():.4f}')\n",
    "            print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "            print('-' * 60)\n",
    "    \n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Wine Quality Classifier...\")\n",
    "print(\"=\" * 60)\n",
    "train_losses, test_losses, train_accs, test_accs = train_wine_classifier(\n",
    "    wine_model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,\n",
    "    lr=0.001, epochs=300, print_every=75\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b734ce",
   "metadata": {},
   "source": [
    "## 7. Model Performance Analysis\n",
    "\n",
    "Analyze the training progress and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bcf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(7, 6))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(train_losses, label='Training Loss', color='blue', linewidth=2)\n",
    "ax1.plot(test_losses, label='Test Loss', color='red', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(train_accs, label='Training Accuracy', color='blue', linewidth=2)\n",
    "ax2.plot(test_accs, label='Test Accuracy', color='red', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Make predictions for detailed analysis\n",
    "wine_model.eval()\n",
    "with torch.no_grad():\n",
    "    train_outputs = wine_model(X_train_tensor)\n",
    "    test_outputs = wine_model(X_test_tensor)\n",
    "    _, train_predicted = torch.max(train_outputs, 1)\n",
    "    _, test_predicted = torch.max(test_outputs, 1)\n",
    "\n",
    "# Convert back to original quality scores for interpretation\n",
    "train_pred_quality = label_encoder.inverse_transform(train_predicted.cpu().numpy())\n",
    "test_pred_quality = label_encoder.inverse_transform(test_predicted.cpu().numpy())\n",
    "train_true_quality = label_encoder.inverse_transform(y_train)\n",
    "test_true_quality = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_true_quality, test_pred_quality)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=unique_classes, yticklabels=unique_classes, ax=ax3)\n",
    "ax3.set_title('Confusion Matrix (Test Set)')\n",
    "ax3.set_xlabel('Predicted Quality')\n",
    "ax3.set_ylabel('True Quality')\n",
    "\n",
    "# Prediction accuracy by quality level\n",
    "quality_accuracy = []\n",
    "for quality in unique_classes:\n",
    "    mask = test_true_quality == quality\n",
    "    if mask.sum() > 0:\n",
    "        acc = (test_pred_quality[mask] == quality).sum() / mask.sum()\n",
    "        quality_accuracy.append(acc)\n",
    "    else:\n",
    "        quality_accuracy.append(0)\n",
    "\n",
    "ax4.bar(unique_classes, quality_accuracy, color='lightgreen', edgecolor='black')\n",
    "ax4.set_xlabel('Quality Score')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.set_title('Classification Accuracy by Quality Level')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, acc in enumerate(quality_accuracy):\n",
    "    ax4.text(unique_classes[i], acc + 0.01, f'{acc:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Accuracy: {train_accs[-1]:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_accs[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a1e8e",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Model Evaluation\n",
    "\n",
    "Detailed evaluation with multiple metrics relevant to quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive metrics\n",
    "test_accuracy = accuracy_score(test_true_quality, test_pred_quality)\n",
    "test_precision = precision_score(test_true_quality, test_pred_quality, average='weighted')\n",
    "test_recall = recall_score(test_true_quality, test_pred_quality, average='weighted')\n",
    "test_f1 = f1_score(test_true_quality, test_pred_quality, average='weighted')\n",
    "\n",
    "print(\"WINE QUALITY CLASSIFICATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Overall Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Weighted Precision:        {test_precision:.4f}\")\n",
    "print(f\"Weighted Recall:           {test_recall:.4f}\")\n",
    "print(f\"Weighted F1-Score:         {test_f1:.4f}\")\n",
    "print()\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(test_true_quality, test_pred_quality, \n",
    "                          target_names=[f'Quality {q}' for q in unique_classes]))\n",
    "\n",
    "# Quality control specific metrics\n",
    "print(\"QUALITY CONTROL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Acceptable quality prediction (Quality >= 6)\n",
    "high_quality_true = (test_true_quality >= 6)\n",
    "high_quality_pred = (test_pred_quality >= 6)\n",
    "\n",
    "hq_precision = precision_score(high_quality_true, high_quality_pred)\n",
    "hq_recall = recall_score(high_quality_true, high_quality_pred)\n",
    "hq_f1 = f1_score(high_quality_true, high_quality_pred)\n",
    "\n",
    "print(f\"High Quality (>=6) Detection:\")\n",
    "print(f\"  Precision: {hq_precision:.4f} (% of predicted high quality that are actually high)\")\n",
    "print(f\"  Recall:    {hq_recall:.4f} (% of actual high quality that are detected)\")\n",
    "print(f\"  F1-Score:  {hq_f1:.4f}\")\n",
    "print()\n",
    "\n",
    "# Quality prediction error analysis\n",
    "prediction_errors = np.abs(test_pred_quality - test_true_quality)\n",
    "mean_error = np.mean(prediction_errors)\n",
    "std_error = np.std(prediction_errors)\n",
    "\n",
    "print(f\"Prediction Error Analysis:\")\n",
    "print(f\"  Mean Absolute Error:     {mean_error:.4f} quality points\")\n",
    "print(f\"  Standard Deviation:      {std_error:.4f} quality points\")\n",
    "print(f\"  Perfect Predictions:     {(prediction_errors == 0).sum()} / {len(prediction_errors)} ({(prediction_errors == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Within ¬±1 quality point: {(prediction_errors <= 1).sum()} / {len(prediction_errors)} ({(prediction_errors <= 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe5ca1",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Understanding which wine properties most influence quality predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b14fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance using gradients (for neural network)\n",
    "def calculate_feature_importance(model, X_data, method='gradient'):\n",
    "    model.eval()\n",
    "    feature_importances = []\n",
    "    \n",
    "    for i in range(len(X_data)):\n",
    "        x_sample = X_data[i:i+1].clone().detach().requires_grad_(True)\n",
    "        output = model(x_sample)\n",
    "        \n",
    "        # Use max probability as the target\n",
    "        loss = output.max()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradient magnitude\n",
    "        importance = x_sample.grad.abs().cpu().numpy().flatten()\n",
    "        feature_importances.append(importance)\n",
    "    \n",
    "    # Average importance across all samples\n",
    "    avg_importance = np.mean(feature_importances, axis=0)\n",
    "    return avg_importance\n",
    "\n",
    "# Calculate feature importance\n",
    "neural_net_importance = calculate_feature_importance(wine_model, X_test_tensor)\n",
    "\n",
    "# Compare with Random Forest importance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_importance = rf_model.feature_importances_\n",
    "\n",
    "# Create feature importance comparison\n",
    "feature_names = X.columns.tolist()\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Neural_Network': neural_net_importance,\n",
    "    'Random_Forest': rf_importance\n",
    "})\n",
    "\n",
    "# Sort by Neural Network importance\n",
    "importance_df = importance_df.sort_values('Neural_Network', ascending=True)\n",
    "\n",
    "# Plot feature importance comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Neural Network importance\n",
    "ax1.barh(importance_df['Feature'], importance_df['Neural_Network'], \n",
    "         color='lightblue', edgecolor='black')\n",
    "ax1.set_xlabel('Importance (Gradient Magnitude)')\n",
    "ax1.set_title('Feature Importance - Neural Network')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Random Forest importance\n",
    "ax2.barh(importance_df['Feature'], importance_df['Random_Forest'], \n",
    "         color='lightcoral', edgecolor='black')\n",
    "ax2.set_xlabel('Importance (Gini Importance)')\n",
    "ax2.set_title('Feature Importance - Random Forest')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"FEATURE IMPORTANCE RANKING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Neural Network (Gradient-based):\")\n",
    "for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['Feature']:<20}: {row['Neural_Network']:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest (Gini-based):\")\n",
    "rf_sorted = importance_df.sort_values('Random_Forest', ascending=False)\n",
    "for i, (_, row) in enumerate(rf_sorted.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['Feature']:<20}: {row['Random_Forest']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac840690",
   "metadata": {},
   "source": [
    "## 10. Interactive Multi-Model Comparison\n",
    "\n",
    "Compare different algorithms for wine quality classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_wine_classification(model_type='Neural Network', \n",
    "                                  hidden_sizes='64,32', \n",
    "                                  learning_rate=0.001, \n",
    "                                  epochs=200):\n",
    "    \"\"\"Interactive wine quality classification with multiple models\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    if model_type == 'Neural Network':\n",
    "        # Parse hidden sizes\n",
    "        try:\n",
    "            hidden_list = [int(x.strip()) for x in hidden_sizes.split(',')]\n",
    "        except:\n",
    "            hidden_list = [64, 32]\n",
    "        \n",
    "        # Create and train neural network\n",
    "        model = WineQualityClassifier(\n",
    "            input_size=X_train_tensor.shape[1],\n",
    "            hidden_sizes=hidden_list,\n",
    "            num_classes=n_classes,\n",
    "            dropout_rate=0.3\n",
    "        ).to(device)\n",
    "        \n",
    "        # Train model\n",
    "        losses = train_wine_classifier(\n",
    "            model, X_train_tensor, y_train_tensor, \n",
    "            X_test_tensor, y_test_tensor,\n",
    "            lr=learning_rate, epochs=epochs, print_every=epochs//4\n",
    "        )\n",
    "        \n",
    "        # Get predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            _, test_predicted = torch.max(test_outputs, 1)\n",
    "        \n",
    "        test_pred_np = test_predicted.cpu().numpy()\n",
    "        test_pred_quality = label_encoder.inverse_transform(test_pred_np)\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = calculate_feature_importance(model, X_test_tensor)\n",
    "        \n",
    "        results['model'] = model\n",
    "        results['training_curves'] = losses\n",
    "        \n",
    "    else:\n",
    "        # Sklearn models\n",
    "        if model_type == 'Random Forest':\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'Gradient Boosting':\n",
    "            model = GradientBoostingClassifier(random_state=42)\n",
    "        elif model_type == 'SVM':\n",
    "            model = SVC(random_state=42)\n",
    "        elif model_type == 'Logistic Regression':\n",
    "            model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        elif model_type == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "            model = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "        else:\n",
    "            print(f\"Model {model_type} not available\")\n",
    "            return\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        test_pred_np = model.predict(X_test_scaled)\n",
    "        test_pred_quality = label_encoder.inverse_transform(test_pred_np)\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            feature_importance = np.abs(model.coef_).mean(0)\n",
    "        else:\n",
    "            feature_importance = np.ones(len(feature_names)) / len(feature_names)\n",
    "        \n",
    "        results['model'] = model\n",
    "        results['training_curves'] = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_true_quality = label_encoder.inverse_transform(y_test)\n",
    "    \n",
    "    accuracy = accuracy_score(test_true_quality, test_pred_quality)\n",
    "    precision = precision_score(test_true_quality, test_pred_quality, average='weighted')\n",
    "    recall = recall_score(test_true_quality, test_pred_quality, average='weighted')\n",
    "    f1 = f1_score(test_true_quality, test_pred_quality, average='weighted')\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    if results['training_curves'] and model_type == 'Neural Network':\n",
    "        # 2x3 layout for neural network\n",
    "        ax1 = plt.subplot(2, 3, 1)\n",
    "        ax2 = plt.subplot(2, 3, 2)\n",
    "        ax3 = plt.subplot(2, 3, 3)\n",
    "        ax4 = plt.subplot(2, 3, 4)\n",
    "        ax5 = plt.subplot(2, 3, 5)\n",
    "        ax6 = plt.subplot(2, 3, 6)\n",
    "        \n",
    "        # Training curves\n",
    "        train_losses, test_losses, train_accs, test_accs = results['training_curves']\n",
    "        \n",
    "        ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "        ax1.plot(test_losses, label='Test Loss', color='red')\n",
    "        ax1.set_title(f'{model_type} - Training Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot(train_accs, label='Train Acc', color='blue')\n",
    "        ax2.plot(test_accs, label='Test Acc', color='red')\n",
    "        ax2.set_title(f'{model_type} - Training Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "    else:\n",
    "        # 2x2 layout for sklearn models\n",
    "        ax3 = plt.subplot(2, 2, 1)\n",
    "        ax4 = plt.subplot(2, 2, 2)\n",
    "        ax5 = plt.subplot(2, 2, 3)\n",
    "        ax6 = plt.subplot(2, 2, 4)\n",
    "        \n",
    "        # Model info\n",
    "        ax3.text(0.5, 0.5, f'{model_type}\\n\\nAccuracy: {accuracy:.3f}\\nPrecision: {precision:.3f}\\nRecall: {recall:.3f}\\nF1-Score: {f1:.3f}', \n",
    "                transform=ax3.transAxes, ha='center', va='center', fontsize=12,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        ax3.set_title(f'{model_type} - Performance')\n",
    "        ax3.axis('off')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(test_true_quality, test_pred_quality)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=unique_classes, yticklabels=unique_classes, ax=ax4)\n",
    "    ax4.set_title(f'{model_type} - Confusion Matrix')\n",
    "    ax4.set_xlabel('Predicted Quality')\n",
    "    ax4.set_ylabel('True Quality')\n",
    "    \n",
    "    # Feature Importance\n",
    "    importance_order = np.argsort(feature_importance)[-10:]  # Top 10 features\n",
    "    ax5.barh(range(len(importance_order)), feature_importance[importance_order])\n",
    "    ax5.set_yticks(range(len(importance_order)))\n",
    "    ax5.set_yticklabels([feature_names[i] for i in importance_order])\n",
    "    ax5.set_title(f'{model_type} - Feature Importance')\n",
    "    ax5.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Quality prediction accuracy\n",
    "    quality_accuracy = []\n",
    "    for quality in unique_classes:\n",
    "        mask = test_true_quality == quality\n",
    "        if mask.sum() > 0:\n",
    "            acc = (test_pred_quality[mask] == quality).sum() / mask.sum()\n",
    "            quality_accuracy.append(acc)\n",
    "        else:\n",
    "            quality_accuracy.append(0)\n",
    "    \n",
    "    ax6.bar(unique_classes, quality_accuracy, color='lightgreen', edgecolor='black')\n",
    "    ax6.set_xlabel('Quality Score')\n",
    "    ax6.set_ylabel('Accuracy')\n",
    "    ax6.set_title(f'{model_type} - Accuracy by Quality')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\n{model_type.upper()} RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Test Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall:         {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    \n",
    "    # Quality control metrics\n",
    "    high_quality_true = (test_true_quality >= 6)\n",
    "    high_quality_pred = (test_pred_quality >= 6)\n",
    "    hq_precision = precision_score(high_quality_true, high_quality_pred)\n",
    "    hq_recall = recall_score(high_quality_true, high_quality_pred)\n",
    "    \n",
    "    print(f\"\\nQuality Control Metrics (High Quality Detection):\")\n",
    "    print(f\"Precision:      {hq_precision:.4f}\")\n",
    "    print(f\"Recall:         {hq_recall:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create model options\n",
    "model_options = ['Neural Network', 'Random Forest', 'Gradient Boosting', \n",
    "                'SVM', 'Logistic Regression']\n",
    "if XGBOOST_AVAILABLE:\n",
    "    model_options.append('XGBoost')\n",
    "\n",
    "# Create interactive widget\n",
    "interact(interactive_wine_classification,\n",
    "         model_type=widgets.Dropdown(options=model_options, value='Neural Network', description='Model:'),\n",
    "         hidden_sizes=widgets.Text(value='64,32,16', description='Hidden Layers:', \n",
    "                                  placeholder='e.g., 64,32,16'),\n",
    "         learning_rate=widgets.FloatSlider(value=0.001, min=0.0001, max=0.01, step=0.0001, description='Learning Rate:'),\n",
    "         epochs=widgets.IntSlider(value=200, min=100, max=500, step=50, description='Epochs:'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4944683",
   "metadata": {},
   "source": [
    "## 11. Industrial Quality Control Applications\n",
    "\n",
    "Let's demonstrate how this model can be used in real industrial quality control scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac780b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_control_dashboard(wine_params):\n",
    "    \"\"\"Simulate a quality control dashboard for wine production\"\"\"\n",
    "    \n",
    "    # Parse input parameters\n",
    "    try:\n",
    "        params = [float(x.strip()) for x in wine_params.split(',')]\n",
    "        if len(params) != 11:\n",
    "            print(\"Error: Please provide exactly 11 parameters\")\n",
    "            return\n",
    "    except:\n",
    "        print(\"Error: Please provide valid numeric parameters\")\n",
    "        return\n",
    "    \n",
    "    # Feature names for reference\n",
    "    param_names = [\n",
    "        'Fixed Acidity', 'Volatile Acidity', 'Citric Acid', 'Residual Sugar',\n",
    "        'Chlorides', 'Free SO2', 'Total SO2', 'Density', 'pH', 'Sulphates', 'Alcohol'\n",
    "    ]\n",
    "    \n",
    "    # Create input array and scale it\n",
    "    input_array = np.array([params]).reshape(1, -1)\n",
    "    input_scaled = scaler.transform(input_array)\n",
    "    input_tensor = torch.FloatTensor(input_scaled).to(device)\n",
    "    \n",
    "    # Make prediction with neural network\n",
    "    wine_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = wine_model(input_tensor)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(output, dim=1)\n",
    "    \n",
    "    # Convert back to quality score\n",
    "    predicted_quality = label_encoder.inverse_transform(predicted_class.cpu().numpy())[0]\n",
    "    confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # Quality assessment\n",
    "    if predicted_quality >= 7:\n",
    "        quality_status = \"EXCELLENT\"\n",
    "        status_color = \"üü¢\"\n",
    "        recommendation = \"Approve for premium market\"\n",
    "    elif predicted_quality >= 6:\n",
    "        quality_status = \"GOOD\"\n",
    "        status_color = \"üü°\"\n",
    "        recommendation = \"Approve for standard market\"\n",
    "    elif predicted_quality >= 5:\n",
    "        quality_status = \"AVERAGE\"\n",
    "        status_color = \"üü†\"\n",
    "        recommendation = \"Consider blending or price adjustment\"\n",
    "    else:\n",
    "        quality_status = \"POOR\"\n",
    "        status_color = \"üî¥\"\n",
    "        recommendation = \"Reject or use for cooking wine\"\n",
    "    \n",
    "    # Display results\n",
    "    print(\"WINE QUALITY CONTROL DASHBOARD\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"INPUT PARAMETERS:\")\n",
    "    for name, value in zip(param_names, params):\n",
    "        print(f\"  {name:<18}: {value:>8.3f}\")\n",
    "    \n",
    "    print(f\"\\nQUALITY ASSESSMENT:\")\n",
    "    print(f\"  Predicted Quality:     {predicted_quality}\")\n",
    "    print(f\"  Confidence:           {confidence:.3f}\")\n",
    "    print(f\"  Status:               {status_color} {quality_status}\")\n",
    "    print(f\"  Recommendation:       {recommendation}\")\n",
    "    \n",
    "    print(f\"\\nPROBABILITY DISTRIBUTION:\")\n",
    "    for i, quality in enumerate(unique_classes):\n",
    "        prob = probabilities[0][i].item()\n",
    "        bar = \"‚ñà\" * int(prob * 30)\n",
    "        print(f\"  Quality {quality}: {prob:.3f} |{bar}\")\n",
    "    \n",
    "    # Parameter analysis\n",
    "    print(f\"\\nPARAMETER ANALYSIS:\")\n",
    "    \n",
    "    # Compare with training data statistics\n",
    "    train_stats = pd.DataFrame(X_train, columns=feature_names).describe()\n",
    "    \n",
    "    issues = []\n",
    "    for i, (name, value) in enumerate(zip(param_names, params)):\n",
    "        feature_name = feature_names[i]\n",
    "        mean_val = train_stats.loc['mean', feature_name]\n",
    "        std_val = train_stats.loc['std', feature_name]\n",
    "        \n",
    "        if abs(value - mean_val) > 2 * std_val:\n",
    "            issues.append(f\"  ‚ö†Ô∏è  {name}: {value:.3f} (unusual, mean: {mean_val:.3f})\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"POTENTIAL ISSUES:\")\n",
    "        for issue in issues:\n",
    "            print(issue)\n",
    "    else:\n",
    "        print(\"  ‚úÖ All parameters within normal ranges\")\n",
    "    \n",
    "    return predicted_quality, confidence\n",
    "\n",
    "# Example usage\n",
    "print(\"QUALITY CONTROL EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: High quality wine\n",
    "print(\"Example 1 - Premium Wine Sample:\")\n",
    "high_quality_params = \"7.4,0.70,0.00,1.9,0.076,11,34,0.9978,3.51,0.56,9.4\"\n",
    "quality_control_dashboard(high_quality_params)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Example 2: Average quality wine\n",
    "print(\"Example 2 - Standard Wine Sample:\")\n",
    "avg_quality_params = \"8.1,0.28,0.40,6.9,0.050,30,97,0.9951,3.26,0.44,10.1\"\n",
    "quality_control_dashboard(avg_quality_params)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Interactive quality control\n",
    "def interactive_quality_control(fixed_acidity=7.4, volatile_acidity=0.7, citric_acid=0.0,\n",
    "                               residual_sugar=1.9, chlorides=0.076, free_sulfur_dioxide=11,\n",
    "                               total_sulfur_dioxide=34, density=0.9978, pH=3.51,\n",
    "                               sulphates=0.56, alcohol=9.4):\n",
    "    \n",
    "    params_string = f\"{fixed_acidity},{volatile_acidity},{citric_acid},{residual_sugar},{chlorides},{free_sulfur_dioxide},{total_sulfur_dioxide},{density},{pH},{sulphates},{alcohol}\"\n",
    "    quality_control_dashboard(params_string)\n",
    "\n",
    "print(\"INTERACTIVE QUALITY CONTROL SYSTEM\")\n",
    "print(\"Adjust the sliders below to test different wine compositions:\")\n",
    "\n",
    "interact(interactive_quality_control,\n",
    "         fixed_acidity=widgets.FloatSlider(value=7.4, min=4.0, max=12.0, step=0.1, description='Fixed Acidity:'),\n",
    "         volatile_acidity=widgets.FloatSlider(value=0.7, min=0.1, max=1.5, step=0.05, description='Volatile Acidity:'),\n",
    "         citric_acid=widgets.FloatSlider(value=0.0, min=0.0, max=0.8, step=0.05, description='Citric Acid:'),\n",
    "         residual_sugar=widgets.FloatSlider(value=1.9, min=0.5, max=15.0, step=0.1, description='Residual Sugar:'),\n",
    "         chlorides=widgets.FloatSlider(value=0.076, min=0.01, max=0.2, step=0.001, description='Chlorides:'),\n",
    "         free_sulfur_dioxide=widgets.IntSlider(value=11, min=1, max=80, step=1, description='Free SO2:'),\n",
    "         total_sulfur_dioxide=widgets.IntSlider(value=34, min=10, max=300, step=5, description='Total SO2:'),\n",
    "         density=widgets.FloatSlider(value=0.9978, min=0.990, max=1.005, step=0.0001, description='Density:'),\n",
    "         pH=widgets.FloatSlider(value=3.51, min=2.5, max=4.0, step=0.01, description='pH:'),\n",
    "         sulphates=widgets.FloatSlider(value=0.56, min=0.3, max=1.5, step=0.01, description='Sulphates:'),\n",
    "         alcohol=widgets.FloatSlider(value=9.4, min=8.0, max=15.0, step=0.1, description='Alcohol %:'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3ec9b",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways and Industrial Applications\n",
    "\n",
    "### **Quality Control Implementation:**\n",
    "- **Automated Grading**: Replace manual quality assessment with consistent ML predictions\n",
    "- **Real-time Monitoring**: Integrate sensors for continuous quality monitoring\n",
    "- **Batch Analysis**: Classify entire production batches for quality assurance\n",
    "- **Process Optimization**: Identify which parameters most affect quality\n",
    "\n",
    "### **Model Performance:**\n",
    "- **Multi-class Classification**: Handle complex quality scales (not just pass/fail)\n",
    "- **Imbalanced Data Handling**: Use class weighting for realistic quality distributions\n",
    "- **Feature Importance**: Understand which measurements are critical for quality\n",
    "- **Confidence Scoring**: Provide uncertainty estimates for decision making\n",
    "\n",
    "### **Industrial Applications:**\n",
    "- **Food & Beverage**: Quality grading for wines, beers, spirits, juices\n",
    "- **Manufacturing**: Product classification by grade/quality level\n",
    "- **Chemical Processing**: Quality assessment based on chemical composition\n",
    "- **Pharmaceuticals**: API quality classification from analytical measurements\n",
    "\n",
    "### **Next Steps:**\n",
    "- Try different feature engineering approaches\n",
    "- Experiment with ensemble methods for better performance\n",
    "- Implement threshold optimization for business objectives\n",
    "- Apply to your own industrial quality control datasets\n",
    "\n",
    "---\n",
    "\n",
    "**This tutorial demonstrates how machine learning can transform quality control from subjective assessments to objective, reproducible classification systems suitable for industrial automation.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
