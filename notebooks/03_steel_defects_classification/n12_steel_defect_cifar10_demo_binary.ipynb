{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f759d146",
   "metadata": {},
   "source": [
    "# Steel Defect Classification Using CIFAR-10 Examples\n",
    "This notebook demonstrates a simple approach to steel defect classification using the CIFAR-10 image dataset. We will treat some CIFAR-10 classes as 'defective' and others as 'non-defective' steel, build a basic neural network, and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c91300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 Dataset\n",
    "# Define transform to convert PIL images to tensors\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Convert to numpy arrays for processing (similar to TensorFlow format)\n",
    "x_train = train_dataset.data  # Shape: (50000, 32, 32, 3)\n",
    "y_train = np.array(train_dataset.targets)  # Shape: (50000,)\n",
    "x_test = test_dataset.data   # Shape: (10000, 32, 32, 3)\n",
    "y_test = np.array(test_dataset.targets)   # Shape: (10000,)\n",
    "\n",
    "print('Train shape:', x_train.shape, y_train.shape)\n",
    "print('Test shape:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de49a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for Steel Defect Classification\n",
    "# CIFAR-10 classes: 0=airplane, 1=automobile, 2=bird, 3=cat, 4=deer, \n",
    "#                   5=dog, 6=frog, 7=horse, 8=ship, 9=truck\n",
    "\n",
    "# For this demo, we'll simulate steel defect classification:\n",
    "# - Class 0 (airplane) will represent 'defective' steel\n",
    "# - Class 1 (automobile) will represent 'non-defective' steel\n",
    "defective_class = 0      # airplane (simulating 'defective' steel)\n",
    "non_defective_class = 1  # automobile (simulating 'non-defective' steel)\n",
    "\n",
    "def select_classes(x, y, class_a, class_b):\n",
    "    \"\"\"Select only two classes from the dataset and convert to binary labels.\"\"\"\n",
    "    idx = np.where((y == class_a) | (y == class_b))[0]\n",
    "    x_selected = x[idx]\n",
    "    y_selected = y[idx]\n",
    "    # Convert to binary: class_a=1 (defective), class_b=0 (non-defective)\n",
    "    y_binary = (y_selected == class_a).astype(np.int64)\n",
    "    return x_selected, y_binary\n",
    "\n",
    "# Extract binary classification data\n",
    "x_train_bin, y_train_bin = select_classes(x_train, y_train, defective_class, non_defective_class)\n",
    "x_test_bin, y_test_bin = select_classes(x_test, y_test, defective_class, non_defective_class)\n",
    "\n",
    "# Normalize pixel values to [0, 1] range and convert to float32\n",
    "x_train_bin = x_train_bin.astype('float32') / 255.0\n",
    "x_test_bin = x_test_bin.astype('float32') / 255.0\n",
    "\n",
    "# Convert from HWC to CHW format for PyTorch (channels first)\n",
    "x_train_bin = np.transpose(x_train_bin, (0, 3, 1, 2))\n",
    "x_test_bin = np.transpose(x_test_bin, (0, 3, 1, 2))\n",
    "\n",
    "print(f'Binary train shape: {x_train_bin.shape}, {y_train_bin.shape}')\n",
    "print(f'Binary test shape: {x_test_bin.shape}, {y_test_bin.shape}')\n",
    "print(f'Training - Defective: {np.sum(y_train_bin)}, Non-defective: {len(y_train_bin) - np.sum(y_train_bin)}')\n",
    "print(f'Testing - Defective: {np.sum(y_test_bin)}, Non-defective: {len(y_test_bin) - np.sum(y_test_bin)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75770ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Simple Neural Network Model using PyTorch\n",
    "class SteelDefectCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SteelDefectCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Calculate the size after convolution and pooling: 16 * 16 * 16 = 4096\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = SteelDefectCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Dataset and DataLoader\n",
    "class SteelDefectDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SteelDefectDataset(x_train_bin, y_train_bin)\n",
    "test_dataset = SteelDefectDataset(x_test_bin, y_test_bin)\n",
    "\n",
    "# Split training data for validation (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Train the Model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted = (output > 0.5).float()\n",
    "            train_total += target.size(0)\n",
    "            train_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data).squeeze()\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                predicted = (output > 0.5).float()\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Calculate averages\n",
    "        train_loss_avg = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_loss_avg = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Store history\n",
    "        history['loss'].append(train_loss_avg)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss_avg)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}] - '\n",
    "              f'Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839468d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            predicted = (output > 0.5).float()\n",
    "            test_total += target.size(0)\n",
    "            test_correct += (predicted == target).sum().item()\n",
    "    \n",
    "    test_loss_avg = test_loss / len(test_loader)\n",
    "    test_acc = test_correct / test_total\n",
    "    \n",
    "    return test_loss_avg, test_acc\n",
    "\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70454cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training History\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef435029",
   "metadata": {},
   "source": [
    "## Model Evaluation and Analysis\n",
    "Now let's thoroughly evaluate our trained model using various metrics and visualizations to understand its performance on the steel defect classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Defects on Sample Images\n",
    "# Get sample data for visualization (convert back to HWC format for display)\n",
    "sample_indices = np.arange(10)\n",
    "sample_images_chw = x_test_bin[sample_indices]  # CHW format\n",
    "sample_labels = y_test_bin[sample_indices]\n",
    "\n",
    "# Convert to PyTorch tensors for prediction\n",
    "sample_tensor = torch.FloatTensor(sample_images_chw).to(device)\n",
    "\n",
    "# Get predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_preds = model(sample_tensor).cpu().numpy().flatten()\n",
    "    sample_preds_binary = (sample_preds > 0.5).astype(int)\n",
    "\n",
    "# Convert images back to HWC format for visualization\n",
    "sample_images_hwc = np.transpose(sample_images_chw, (0, 2, 3, 1))\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(sample_images_hwc[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Get actual and predicted labels\n",
    "    actual = 'Defective' if sample_labels[i] == 1 else 'Non-defective'\n",
    "    predicted = 'Defective' if sample_preds_binary[i] == 1 else 'Non-defective'\n",
    "    confidence = sample_preds[i]\n",
    "    \n",
    "    # Color code: green for correct, red for incorrect\n",
    "    color = 'green' if sample_labels[i] == sample_preds_binary[i] else 'red'\n",
    "    \n",
    "    plt.title(f'Actual: {actual}\\nPred: {predicted}\\nConf: {confidence:.2f}', \n",
    "              fontsize=8, color=color)\n",
    "\n",
    "plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sample accuracy: {np.mean(sample_labels == sample_preds_binary):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f727b",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We Accomplished\n",
    "This notebook demonstrated a complete binary classification pipeline for steel defect detection using PyTorch:\n",
    "- **Data Preparation**: Selected and preprocessed CIFAR-10 classes to simulate defective vs non-defective steel\n",
    "- **Model Architecture**: Built a simple CNN with convolutional, pooling, and dense layers using PyTorch\n",
    "- **Training**: Implemented custom training loop with validation monitoring\n",
    "- **Evaluation**: Comprehensive performance analysis using multiple metrics\n",
    "\n",
    "### Key Insights\n",
    "- The PyTorch model can distinguish between the two simulated classes with reasonable accuracy\n",
    "- Custom training loop provides full control over the training process\n",
    "- Training and validation curves help identify potential overfitting or underfitting\n",
    "- Confusion matrix provides detailed classification performance breakdown\n",
    "- Sample predictions show model confidence and error patterns\n",
    "\n",
    "### PyTorch Implementation Benefits\n",
    "- **Flexibility**: Full control over training loop and model architecture\n",
    "- **GPU Support**: Automatic GPU acceleration when available\n",
    "- **Dynamic Graphs**: Easier debugging and model modification\n",
    "- **Production Ready**: Better deployment options for industrial applications\n",
    "\n",
    "### For Real-World Steel Defect Classification\n",
    "To adapt this PyTorch approach for actual steel defect detection:\n",
    "\n",
    "1. **Dataset**: Replace CIFAR-10 with real steel surface images containing actual defects\n",
    "2. **Data Augmentation**: Add rotation, scaling, brightness adjustments using torchvision.transforms\n",
    "3. **Advanced Architecture**: Consider transfer learning with pre-trained models (ResNet, EfficientNet from torchvision)\n",
    "4. **Multi-class Classification**: Extend to classify different types of defects (scratches, rust, dents, etc.)\n",
    "5. **Real-time Inference**: Optimize model for deployment using TorchScript or ONNX\n",
    "6. **Data Quality**: Ensure proper labeling and balanced datasets for each defect type\n",
    "\n",
    "### Performance Considerations\n",
    "- **Precision vs Recall**: In defect detection, high recall (catching all defects) might be more important than precision\n",
    "- **False Positives vs False Negatives**: Consider the cost of missing a defect vs incorrectly flagging good steel\n",
    "- **Industrial Requirements**: Model performance should meet quality control standards and processing speed requirements\n",
    "- **Hardware Optimization**: PyTorch enables efficient deployment on various hardware platforms including edge devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for evaluation metrics\n",
    "def get_all_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data).squeeze()\n",
    "            \n",
    "            predicted = (output > 0.5).float()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(output.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "y_pred, y_pred_proba, y_true = get_all_predictions(model, test_loader)\n",
    "\n",
    "# Confusion matrix and all metrics for binary classification\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== Model Evaluation Metrics ===\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-defective', 'Defective'], \n",
    "            yticklabels=['Non-defective', 'Defective'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Steel Defect Classification')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Metrics\n",
    "print(f'Accuracy: {accuracy_score(y_true, y_pred):.4f}')\n",
    "print(f'Precision: {precision_score(y_true, y_pred):.4f}')\n",
    "print(f'Recall: {recall_score(y_true, y_pred):.4f}')\n",
    "print(f'F1 Score: {f1_score(y_true, y_pred):.4f}')\n",
    "print('\\nDetailed Classification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-defective', 'Defective']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
