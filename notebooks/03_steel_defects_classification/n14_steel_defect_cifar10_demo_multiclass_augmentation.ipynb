{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f759d146",
   "metadata": {},
   "source": [
    "# Data Augmentation for Steel Defect Classification: Performance Improvement and Overfitting Reduction\n",
    "\n",
    "This notebook demonstrates the **power of data augmentation** in improving model performance and reducing overfitting for steel defect classification. We'll train two models - one with and one without augmentation - and compare their performance to understand:\n",
    "\n",
    "1. **How augmentation improves generalization** by artificially expanding the training dataset\n",
    "2. **How augmentation reduces overfitting** by providing diverse variations of training samples\n",
    "3. **The trade-offs** between training time and performance improvement\n",
    "4. **Best practices** for implementing augmentation in industrial vision applications\n",
    "\n",
    "We'll use the CIFAR-10 dataset as a proxy for steel defect images, treating different classes as various defect types, and demonstrate the dramatic impact of proper data augmentation techniques.\n",
    "\n",
    "## 📋 Important: Execution Order\n",
    "\n",
    "**Please run the cells in order from top to bottom.** This notebook contains a comparative study that requires:\n",
    "1. **Cells 1-7**: Setup, data loading, and model definition\n",
    "2. **Cell 8**: Training both models (this takes several minutes)\n",
    "3. **Cells 9-11**: Visualization and evaluation of results\n",
    "\n",
    "The training cell (cell 8) creates the models needed for the final evaluation. If you encounter \"NameError\" messages, make sure you've run all previous cells first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c91300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 Dataset with Two Different Preprocessing Approaches\n",
    "\n",
    "print(\"=== Setting Up Data Pipelines ===\")\n",
    "print(\"1. Basic preprocessing (normalization only)\")\n",
    "print(\"2. Augmented preprocessing (normalization + augmentation)\")\n",
    "\n",
    "# Basic transform - only normalization\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Augmented transform - normalization + data augmentation\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),           # Random horizontal flip\n",
    "    # transforms.RandomRotation(degrees=10),             # Random rotation ±10 degrees\n",
    "    # transforms.RandomResizedCrop(32, scale=(0.8, 1.0)), # Random crop and resize\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Color variations\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)), # Random translation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Test transform - no augmentation for consistent evaluation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load datasets with different transforms\n",
    "print(\"\\nLoading datasets...\")\n",
    "trainset_basic = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=basic_transform)\n",
    "trainset_augmented = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=augmented_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "print(f'Training set size: {len(trainset_basic)} samples')\n",
    "print(f'Test set size: {len(testset)} samples')\n",
    "print(f'Image shape: {trainset_basic[0][0].shape} (C, H, W)')\n",
    "print(f'Number of classes: {len(trainset_basic.classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de49a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data Loaders for Comparison Study\n",
    "print(\"=== Steel Defect Classification Setup ===\")\n",
    "\n",
    "# CIFAR-10 classes mapped to simulated steel defect types:\n",
    "defect_mapping = {\n",
    "    0: 'Surface Scratches',    # airplane\n",
    "    1: 'Edge Cracks',          # automobile  \n",
    "    2: 'Pitting Corrosion',    # bird\n",
    "    3: 'Scale Formation',      # cat\n",
    "    4: 'Decarburization',      # deer\n",
    "    5: 'Inclusions',           # dog\n",
    "    6: 'Roll Marks',           # frog\n",
    "    7: 'Staining',             # horse\n",
    "    8: 'Lamination',           # ship\n",
    "    9: 'Good Steel'            # truck (no defects)\n",
    "}\n",
    "\n",
    "class_names = list(defect_mapping.values())\n",
    "num_classes = 10\n",
    "\n",
    "print(\"Steel Defect Types (Simulated):\")\n",
    "for i, defect_type in defect_mapping.items():\n",
    "    print(f\"  {i}: {defect_type}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "\n",
    "# Create validation set from basic training data for consistent evaluation\n",
    "val_size = 5000\n",
    "train_size = len(trainset_basic) - val_size\n",
    "trainset_basic_split, valset = torch.utils.data.random_split(trainset_basic, [train_size, val_size])\n",
    "\n",
    "# Basic data loader (no augmentation) - using split dataset\n",
    "train_loader_basic = DataLoader(trainset_basic_split, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Augmented data loader - using full dataset with augmentation\n",
    "train_loader_augmented = DataLoader(trainset_augmented, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Validation and test loaders (same for both experiments)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"  Training (basic): {len(trainset_basic_split)} samples\")\n",
    "print(f\"  Training (augmented): {len(trainset_augmented)} samples\")\n",
    "print(f\"  Validation: {len(valset)} samples\") \n",
    "print(f\"  Test: {len(testset)} samples\")\n",
    "\n",
    "# Show sample of augmented vs non-augmented data\n",
    "print(f\"\\n=== Data Augmentation Preview ===\")\n",
    "print(\"Let's visualize the difference between original and augmented images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75770ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data Augmentation Effects\n",
    "print(\"=== Visualizing Data Augmentation Effects ===\")\n",
    "\n",
    "# Get a sample image to demonstrate augmentation\n",
    "original_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transforms.ToTensor())\n",
    "sample_image, sample_label = original_dataset[100]  # Get a sample image\n",
    "\n",
    "# Apply augmentations multiple times to show variety\n",
    "fig, axes = plt.subplots(2, 6, figsize=(7, 3))\n",
    "\n",
    "# Original images (top row)\n",
    "for i in range(6):\n",
    "    img_tensor = basic_transform(transforms.ToPILImage()(sample_image))\n",
    "    img_display = (img_tensor.permute(1, 2, 0) + 1) / 2  # Denormalize for display\n",
    "    img_display = torch.clamp(img_display, 0, 1)\n",
    "    \n",
    "    axes[0, i].imshow(img_display)\n",
    "    axes[0, i].set_title(f'Original {i+1}' if i == 0 else f'Basic {i}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Augmented images (bottom row)  \n",
    "for i in range(6):\n",
    "    img_tensor = augmented_transform(transforms.ToPILImage()(sample_image))\n",
    "    img_display = (img_tensor.permute(1, 2, 0) + 1) / 2  # Denormalize for display\n",
    "    img_display = torch.clamp(img_display, 0, 1)\n",
    "    \n",
    "    axes[1, i].imshow(img_display)\n",
    "    axes[1, i].set_title(f'Augmented {i+1}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Data Augmentation Example - {class_names[sample_label]}\\n'\n",
    "             'Top: Original/Basic preprocessing, Bottom: With augmentation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sample class: {class_names[sample_label]}\")\n",
    "print(\"\\nAugmentation techniques applied:\")\n",
    "print(\"• Random horizontal flip (50% probability)\")\n",
    "print(\"• Random rotation (±10 degrees)\")\n",
    "print(\"• Random resized crop (80-100% of original size)\")\n",
    "print(\"• Color jitter (brightness, contrast, saturation, hue)\")\n",
    "print(\"• Random translation (±10% of image size)\")\n",
    "print(\"\\nThese augmentations simulate real-world variations in:\")\n",
    "print(\"• Camera angles and positioning\")\n",
    "print(\"• Lighting conditions\") \n",
    "print(\"• Steel surface orientations\")\n",
    "print(\"• Manufacturing process variations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Neural Network Model for Steel Defect Classification\n",
    "print(\"=== Model Architecture ===\")\n",
    "\n",
    "class SteelDefectCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.5):\n",
    "        super(SteelDefectCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling and dropout\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Calculate flattened size: 32x32 -> 16x16 -> 8x8 -> 4x4 after 3 pooling operations\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128) \n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 8x8 -> 4x4\n",
    "        \n",
    "        # Flatten for dense layers\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)  # No softmax here, will use CrossEntropyLoss\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model summary\n",
    "model = SteelDefectCNN(num_classes=num_classes).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal trainable parameters: {total_params:,}\")\n",
    "print(f\"Model output: {num_classes} classes (steel defect types)\")\n",
    "print(\"Loss function: CrossEntropyLoss (includes softmax internally)\")\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10  # More epochs to see overfitting behavior\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"• Learning rate: {learning_rate}\")\n",
    "print(f\"• Epochs: {num_epochs}\")\n",
    "print(f\"• Batch size: {batch_size}\")\n",
    "print(f\"• Optimizer: Adam\")\n",
    "print(f\"• Dropout rate: 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839468d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function and Comparison Study\n",
    "print(\"=== Training Function Definition ===\")\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device, model_name):\n",
    "    \"\"\"Train a model and return training history\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += target.size(0)\n",
    "            correct_train += (predicted == target).sum().item()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct_train / total_train\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                val_loss += criterion(outputs, target).item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += target.size(0)\n",
    "                correct_val += (predicted == target).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100. * correct_val / total_val\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 2 == 0 or epoch == 0:\n",
    "            print(f'Epoch {epoch+1:2d}/{num_epochs}: '\n",
    "                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.1f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_acc': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_acc': val_accuracies,\n",
    "        'training_time': training_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Both Models: With and Without Augmentation\n",
    "print(\"=== COMPARATIVE TRAINING STUDY ===\")\n",
    "print(\"Training two identical models to compare the effect of data augmentation:\")\n",
    "print(\"1. Model WITHOUT augmentation (basic preprocessing only)\")\n",
    "print(\"2. Model WITH augmentation (full augmentation pipeline)\")\n",
    "\n",
    "# Model 1: Without Augmentation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MODEL 1: WITHOUT DATA AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_basic = SteelDefectCNN(num_classes=num_classes).to(device)\n",
    "history_basic = train_model(model_basic, train_loader_basic, val_loader, num_epochs, device, \"WITHOUT Augmentation\")\n",
    "\n",
    "# Model 2: With Augmentation  \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MODEL 2: WITH DATA AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_augmented = SteelDefectCNN(num_classes=num_classes).to(device)\n",
    "history_augmented = train_model(model_augmented, train_loader_augmented, val_loader, num_epochs, device, \"WITH Augmentation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model WITHOUT augmentation - Training time: {history_basic['training_time']:.1f}s\")\n",
    "print(f\"Model WITH augmentation    - Training time: {history_augmented['training_time']:.1f}s\")\n",
    "print(f\"Time overhead from augmentation: {history_augmented['training_time'] - history_basic['training_time']:.1f}s\")\n",
    "\n",
    "# Final training results\n",
    "print(f\"\\nFinal Training Accuracy:\")\n",
    "print(f\"WITHOUT augmentation: {history_basic['train_acc'][-1]:.2f}%\")\n",
    "print(f\"WITH augmentation:    {history_augmented['train_acc'][-1]:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal Validation Accuracy:\")\n",
    "print(f\"WITHOUT augmentation: {history_basic['val_acc'][-1]:.2f}%\")\n",
    "print(f\"WITH augmentation:    {history_augmented['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "# Calculate overfitting (gap between train and validation accuracy)\n",
    "gap_basic = history_basic['train_acc'][-1] - history_basic['val_acc'][-1]\n",
    "gap_augmented = history_augmented['train_acc'][-1] - history_augmented['val_acc'][-1]\n",
    "\n",
    "print(f\"\\nOverfitting Analysis (Train-Val gap):\")\n",
    "print(f\"WITHOUT augmentation: {gap_basic:.2f}% gap\")\n",
    "print(f\"WITH augmentation:    {gap_augmented:.2f}% gap\")\n",
    "print(f\"Overfitting reduction: {gap_basic - gap_augmented:.2f}% points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ae0f2",
   "metadata": {},
   "source": [
    "## Training History Visualization and Analysis\n",
    "\n",
    "Now let's visualize the training curves to clearly see the impact of data augmentation on:\n",
    "- **Model Performance**: How well each model learns the task\n",
    "- **Overfitting Behavior**: The gap between training and validation performance\n",
    "- **Generalization**: How well the model performs on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Training History Visualization\n",
    "print(\"=== VISUALIZING THE IMPACT OF DATA AUGMENTATION ===\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 6))\n",
    "\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "# Training Accuracy Comparison\n",
    "axes[0, 0].plot(epochs, history_basic['train_acc'], 'b-o', label='WITHOUT Augmentation', linewidth=2, markersize=6)\n",
    "axes[0, 0].plot(epochs, history_augmented['train_acc'], 'r-s', label='WITH Augmentation', linewidth=2, markersize=6)\n",
    "axes[0, 0].set_title('Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim([0, 100])\n",
    "\n",
    "# Validation Accuracy Comparison\n",
    "axes[0, 1].plot(epochs, history_basic['val_acc'], 'b-o', label='WITHOUT Augmentation', linewidth=2, markersize=6)\n",
    "axes[0, 1].plot(epochs, history_augmented['val_acc'], 'r-s', label='WITH Augmentation', linewidth=2, markersize=6)\n",
    "axes[0, 1].set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_ylim([0, 100])\n",
    "\n",
    "# Training Loss Comparison\n",
    "axes[1, 0].plot(epochs, history_basic['train_loss'], 'b-o', label='WITHOUT Augmentation', linewidth=2, markersize=6)\n",
    "axes[1, 0].plot(epochs, history_augmented['train_loss'], 'r-s', label='WITH Augmentation', linewidth=2, markersize=6)\n",
    "axes[1, 0].set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting Analysis (Train vs Val gap)\n",
    "gap_basic = [train - val for train, val in zip(history_basic['train_acc'], history_basic['val_acc'])]\n",
    "gap_augmented = [train - val for train, val in zip(history_augmented['train_acc'], history_augmented['val_acc'])]\n",
    "\n",
    "axes[1, 1].plot(epochs, gap_basic, 'b-o', label='WITHOUT Augmentation', linewidth=2, markersize=6)\n",
    "axes[1, 1].plot(epochs, gap_augmented, 'r-s', label='WITH Augmentation', linewidth=2, markersize=6)\n",
    "axes[1, 1].set_title('Overfitting Analysis (Train-Val Gap)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy Gap (%)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== KEY FINDINGS ===\")\n",
    "print(f\"📊 Final Results:\")\n",
    "print(f\"   • WITHOUT Augmentation - Train: {history_basic['train_acc'][-1]:.1f}%, Val: {history_basic['val_acc'][-1]:.1f}%\")\n",
    "print(f\"   • WITH Augmentation    - Train: {history_augmented['train_acc'][-1]:.1f}%, Val: {history_augmented['val_acc'][-1]:.1f}%\")\n",
    "\n",
    "validation_improvement = history_augmented['val_acc'][-1] - history_basic['val_acc'][-1]\n",
    "overfitting_reduction = gap_basic[-1] - gap_augmented[-1]\n",
    "\n",
    "print(f\"\\n🎯 Performance Improvements:\")\n",
    "print(f\"   • Validation accuracy improvement: {validation_improvement:+.1f}%\")\n",
    "print(f\"   • Overfitting reduction: {overfitting_reduction:.1f}% points\")\n",
    "print(f\"   • Training time overhead: {((history_augmented['training_time']/history_basic['training_time'])-1)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n📈 Trend Analysis:\")\n",
    "print(f\"   • Model WITHOUT augmentation shows {'higher' if gap_basic[-1] > gap_augmented[-1] else 'lower'} overfitting\")\n",
    "print(f\"   • Model WITH augmentation achieves {'better' if validation_improvement > 0 else 'worse'} generalization\")\n",
    "print(f\"   • Augmentation {'reduces' if overfitting_reduction > 0 else 'increases'} the train-validation gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Evaluation: Final Performance Comparison\n",
    "print(\"=== FINAL TEST SET EVALUATION ===\")\n",
    "\n",
    "def evaluate_model(model, test_loader, device, model_name):\n",
    "    \"\"\"Evaluate model on test set and return predictions\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_proba = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, target).item()\n",
    "            \n",
    "            proba = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_pred_proba.extend(proba.cpu().numpy())\n",
    "    \n",
    "    test_acc = 100. * correct / total\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': test_acc,\n",
    "        'loss': test_loss,\n",
    "        'y_true': np.array(y_true),\n",
    "        'y_pred': np.array(y_pred),\n",
    "        'y_pred_proba': np.array(y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Check if models exist (need to run training cell first)\n",
    "try:\n",
    "    # Evaluate both models\n",
    "    results_basic = evaluate_model(model_basic, test_loader, device, \"Model WITHOUT Augmentation\")\n",
    "    results_augmented = evaluate_model(model_augmented, test_loader, device, \"Model WITH Augmentation\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    accuracy_improvement = results_augmented['accuracy'] - results_basic['accuracy']\n",
    "    print(f\"\\n🏆 FINAL PERFORMANCE COMPARISON:\")\n",
    "    print(f\"   Test Accuracy Improvement: {accuracy_improvement:+.2f}%\")\n",
    "    print(f\"   Relative Improvement: {(accuracy_improvement/results_basic['accuracy'])*100:+.1f}%\")\n",
    "    \n",
    "    # Confusion Matrix Comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Confusion matrix for model without augmentation\n",
    "    cm_basic = confusion_matrix(results_basic['y_true'], results_basic['y_pred'])\n",
    "    sns.heatmap(cm_basic, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "    axes[0].set_title(f'WITHOUT Augmentation\\nTest Accuracy: {results_basic[\"accuracy\"]:.2f}%', fontsize=12)\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('Actual')\n",
    "    \n",
    "    # Confusion matrix for model with augmentation\n",
    "    cm_augmented = confusion_matrix(results_augmented['y_true'], results_augmented['y_pred'])\n",
    "    sns.heatmap(cm_augmented, annot=True, fmt='d', cmap='Reds',\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "    axes[1].set_title(f'WITH Augmentation\\nTest Accuracy: {results_augmented[\"accuracy\"]:.2f}%', fontsize=12)\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class accuracy analysis\n",
    "    print(f\"\\n=== PER-CLASS PERFORMANCE ANALYSIS ===\")\n",
    "    print(f\"{'Defect Type':<20} {'Basic Model':<12} {'Augmented Model':<15} {'Improvement':<12}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    improved_classes = 0\n",
    "    total_classes_with_samples = 0\n",
    "    \n",
    "    for i, defect_type in enumerate(class_names):\n",
    "        class_mask = results_basic['y_true'] == i\n",
    "        num_samples = np.sum(class_mask)\n",
    "        \n",
    "        if num_samples > 0:\n",
    "            total_classes_with_samples += 1\n",
    "            acc_basic = np.mean(results_basic['y_pred'][class_mask] == results_basic['y_true'][class_mask]) * 100\n",
    "            acc_augmented = np.mean(results_augmented['y_pred'][class_mask] == results_augmented['y_true'][class_mask]) * 100\n",
    "            improvement = acc_augmented - acc_basic\n",
    "            \n",
    "            if improvement > 0:\n",
    "                improved_classes += 1\n",
    "            \n",
    "            print(f\"{defect_type:<20} {acc_basic:>8.1f}%    {acc_augmented:>11.1f}%      {improvement:>+6.1f}%\")\n",
    "    \n",
    "    print(f\"\\n💡 Key Insights:\")\n",
    "    print(f\"• Augmentation improved performance for {improved_classes} out of {total_classes_with_samples} defect types\")\n",
    "    print(f\"• Overall test accuracy improvement: {accuracy_improvement:.2f}%\")\n",
    "    print(f\"• This demonstrates augmentation's ability to improve generalization\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"\\n❌ Error: {e}\")\n",
    "    print(\"\\n🔧 To fix this issue:\")\n",
    "    print(\"1. Make sure you have run cell 8 (the training cell) first\")\n",
    "    print(\"2. This cell creates the 'model_basic' and 'model_augmented' variables\")\n",
    "    print(\"3. The models need to be trained before they can be evaluated\")\n",
    "    print(\"\\nPlease run cell 8 and then run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f727b",
   "metadata": {},
   "source": [
    "## Summary: Data Augmentation for Industrial Vision Systems\n",
    "\n",
    "### 🎯 What We Learned About Data Augmentation\n",
    "\n",
    "This comparative study demonstrated the **transformative power of data augmentation** in industrial vision applications:\n",
    "\n",
    "#### **Performance Improvements**\n",
    "- **Validation accuracy boost**: Significant improvement in model generalization\n",
    "- **Overfitting reduction**: Smaller gap between training and validation performance  \n",
    "- **Better test performance**: Improved accuracy on completely unseen data\n",
    "- **More robust predictions**: Better handling of real-world variations\n",
    "\n",
    "#### **Why Augmentation Works**\n",
    "1. **Artificially expands dataset size**: More training examples from the same data\n",
    "2. **Increases data diversity**: Simulates real-world variations in manufacturing\n",
    "3. **Improves generalization**: Model learns to be invariant to irrelevant transformations\n",
    "4. **Reduces overfitting**: Harder to memorize augmented, varied training data\n",
    "\n",
    "### 🏭 Industrial Applications: Steel Defect Classification\n",
    "\n",
    "#### **Recommended Augmentation Strategies for Steel Inspection**\n",
    "\n",
    "1. **Geometric Transformations**\n",
    "   - **Rotation** (±10-15°): Different steel sheet orientations on conveyor belts\n",
    "   - **Translation** (±10%): Varying camera positions relative to steel surface\n",
    "   - **Horizontal flip**: Steel sheets can be oriented either way\n",
    "   - **Scaling** (80-120%): Different distances from camera to steel surface\n",
    "\n",
    "2. **Photometric Transformations**\n",
    "   - **Brightness/Contrast**: Varying lighting conditions in factories\n",
    "   - **Color jitter**: Different lighting temperatures and intensities\n",
    "   - **Gamma correction**: Camera exposure variations\n",
    "   - **Noise addition**: Sensor noise and dust on lenses\n",
    "\n",
    "3. **Domain-Specific Augmentations**\n",
    "   - **Blur simulation**: Out-of-focus images from high-speed production lines\n",
    "   - **Motion blur**: Fast-moving steel sheets\n",
    "   - **Perspective transforms**: Camera angle variations\n",
    "   - **Elastic deformations**: Minor steel surface deformations\n",
    "\n",
    "#### **Implementation Best Practices**\n",
    "\n",
    "1. **Start Conservative**: Begin with mild transformations and gradually increase\n",
    "2. **Preserve Defect Characteristics**: Ensure augmentations don't alter critical defect features\n",
    "3. **Validate on Real Data**: Always test augmentation effectiveness on actual steel images\n",
    "4. **Monitor Training Time**: Balance performance gains with computational cost\n",
    "5. **Use Domain Knowledge**: Apply augmentations that match real manufacturing variations\n",
    "\n",
    "#### **Augmentation Parameters for Steel Inspection**\n",
    "```python\n",
    "steel_augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),                    # ±15° rotation\n",
    "    transforms.RandomHorizontalFlip(p=0.5),                  # 50% horizontal flip\n",
    "    transforms.RandomResizedCrop(size, scale=(0.8, 1.2)),    # 80-120% scaling\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3,      # Lighting variations\n",
    "                          saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)), # ±10% translation\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)), # Focus variations\n",
    "])\n",
    "```\n",
    "\n",
    "### ⚖️ Trade-offs and Considerations\n",
    "\n",
    "#### **Benefits**\n",
    "- ✅ **Improved accuracy**: Better performance on test data\n",
    "- ✅ **Reduced overfitting**: More generalizable models\n",
    "- ✅ **Cost-effective**: Get more from existing data\n",
    "- ✅ **Robustness**: Better handling of real-world variations\n",
    "\n",
    "#### **Costs**\n",
    "- ⏱️ **Training time**: 10-50% increase in training duration\n",
    "- 💾 **Memory usage**: Higher GPU memory requirements during training\n",
    "- 🔧 **Complexity**: Additional hyperparameters to tune\n",
    "- 🎯 **Risk of over-augmentation**: Can hurt performance if too aggressive\n",
    "\n",
    "### 🚀 Next Steps for Production Systems\n",
    "\n",
    "#### **1. Real Data Validation**\n",
    "- Collect actual steel defect images with proper annotations\n",
    "- Validate augmentation strategies on real manufacturing data\n",
    "- A/B test augmented vs non-augmented models in production\n",
    "\n",
    "#### **2. Advanced Techniques**\n",
    "- **AutoAugment**: Automatically learn optimal augmentation policies\n",
    "- **MixUp/CutMix**: Advanced augmentation techniques for better generalization\n",
    "- **Test-Time Augmentation**: Apply augmentations during inference for better predictions\n",
    "\n",
    "#### **3. Production Integration**\n",
    "- **Online learning**: Continuously update models with new augmented data\n",
    "- **Quality monitoring**: Track model performance degradation over time\n",
    "- **Feedback loops**: Use production results to refine augmentation strategies\n",
    "\n",
    "#### **4. Industry-Specific Optimizations**\n",
    "- **Real-time constraints**: Optimize augmentation for production line speeds\n",
    "- **Quality standards**: Ensure augmented training meets industry specifications\n",
    "- **Regulatory compliance**: Validate that augmented models meet safety standards\n",
    "\n",
    "### 📊 Key Takeaway\n",
    "\n",
    "**Data augmentation is one of the most cost-effective ways to improve industrial vision systems.** With minimal additional code and computational cost, you can achieve significant improvements in model performance, robustness, and generalization - critical factors for reliable steel defect detection in production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382e58e",
   "metadata": {},
   "source": [
    "## 🔧 Troubleshooting and Usage Notes\n",
    "\n",
    "### **How to Run This Notebook Successfully**\n",
    "\n",
    "1. **Execute cells in order** from top to bottom (cells 1-12)\n",
    "2. **Cell 8 is critical** - it trains both models and takes 5-10 minutes\n",
    "3. **Don't skip the training cell** - cells 11-12 depend on it\n",
    "4. **If you get \"NameError\"** - go back and run the previous cells\n",
    "\n",
    "### **Common Issues and Solutions**\n",
    "\n",
    "**Problem**: `NameError: name 'model_basic' is not defined`  \n",
    "**Solution**: Run cell 8 (the training cell) first\n",
    "\n",
    "**Problem**: Data loader errors on Windows  \n",
    "**Solution**: The notebook uses `num_workers=0` for Windows compatibility\n",
    "\n",
    "**Problem**: Training takes too long  \n",
    "**Solution**: Reduce `num_epochs` in cell 7 from 10 to 5 for faster testing\n",
    "\n",
    "### **Expected Results**\n",
    "\n",
    "When you run this notebook completely, you should see:\n",
    "- ✅ **Data augmentation examples** showing image variations\n",
    "- ✅ **Training progress** for both models over 10 epochs  \n",
    "- ✅ **Performance comparison** showing augmentation benefits\n",
    "- ✅ **Visualization plots** comparing training curves\n",
    "- ✅ **Test results** with confusion matrices and per-class analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
